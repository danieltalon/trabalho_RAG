{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR3Tv36b11S+x0zqwuousb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieltalon/trabalho_RAG/blob/main/1_ler_json_com_perguntas_classificar_gerar_novo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tu_xHjffA6Rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98d64e6e-d77c-4a38-d277-79b54be2f22b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key carregada com sucesso.\n",
            "Modelo Gemini 'gemini-1.5-flash' configurado.\n",
            "\n",
            "Tentando ler o arquivo de entrada: /content/questoes-Revalida+Fuvest.json\n",
            "Arquivo '/content/questoes-Revalida+Fuvest.json' lido com sucesso. 1301 questões encontradas no total.\n",
            "\n",
            "Filtrado para o(s) ano(s): 2024, 2023, 2022, 2021. 670 questões encontradas.\n",
            "Número de questões filtradas (670) é menor ou igual ao limite (700). Processando todas as filtradas.\n",
            "\n",
            "Iniciando classificação de 670 questões em lotes...\n",
            "Processando em 27 lotes de até 25 questões cada.\n",
            "\n",
            "Processando Lote 1/27 (Questões 1 a 25)...\n",
            "  Lote 1 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 2/27 (Questões 26 a 50)...\n",
            "  Lote 2 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 3/27 (Questões 51 a 75)...\n",
            "  Lote 3 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 4/27 (Questões 76 a 100)...\n",
            "  Lote 4 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 5/27 (Questões 101 a 125)...\n",
            "  Lote 5 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 6/27 (Questões 126 a 150)...\n",
            "  Lote 6 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 7/27 (Questões 151 a 175)...\n",
            "  Lote 7 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 8/27 (Questões 176 a 200)...\n",
            "  Lote 8 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 9/27 (Questões 201 a 225)...\n",
            "  Lote 9 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 10/27 (Questões 226 a 250)...\n",
            "  Lote 10 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 11/27 (Questões 251 a 275)...\n",
            "  Lote 11 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 12/27 (Questões 276 a 300)...\n",
            "  Lote 12 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 13/27 (Questões 301 a 325)...\n",
            "  Lote 13 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 14/27 (Questões 326 a 350)...\n",
            "  Lote 14 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 15/27 (Questões 351 a 375)...\n",
            "  Lote 15 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 16/27 (Questões 376 a 400)...\n",
            "  Lote 16 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 17/27 (Questões 401 a 425)...\n",
            "  Lote 17 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 18/27 (Questões 426 a 450)...\n",
            "  Lote 18 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 19/27 (Questões 451 a 475)...\n",
            "  Lote 19 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 20/27 (Questões 476 a 500)...\n",
            "  Lote 20 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 21/27 (Questões 501 a 525)...\n",
            "  Lote 21 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 22/27 (Questões 526 a 550)...\n",
            "  Lote 22 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 23/27 (Questões 551 a 575)...\n",
            "  Lote 23 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 24/27 (Questões 576 a 600)...\n",
            "  Lote 24 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 25/27 (Questões 601 a 625)...\n",
            "  Lote 25 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 26/27 (Questões 626 a 650)...\n",
            "  Lote 26 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Processando Lote 27/27 (Questões 651 a 670)...\n",
            "  Lote 27 concluído. Pausando por 6 segundos...\n",
            "\n",
            "Salvando os resultados classificados em: /content/questoes_2021_2022_2023_2024_limit700_classificadas_lote.json\n",
            "Arquivo salvo com sucesso!\n",
            "\n",
            "--- Resumo da Classificação por Área ---\n",
            "Anos processados: 2024, 2023, 2022, 2021 (limitado a 700)\n",
            "Total de questões processadas: 670\n",
            "Questões classificadas com sucesso: 670\n",
            "Questões com erro na chamada da API (Quota/Conexão/Outros): 0\n",
            "Questões com erro no parse da resposta da IA: 0\n",
            "Questões não retornadas pela IA dentro de um lote: 0\n",
            "--------------------\n",
            "Contagem por área (excluindo erros/não classificados):\n",
            "Clínica Médica Geral: 260 questões\n",
            "Urgência/Emergência: 155 questões\n",
            "Infectologia: 140 questões\n",
            "Pediatria: 137 questões\n",
            "Ginecologia: 129 questões\n",
            "Gastroenterologia: 89 questões\n",
            "Cirurgia Geral: 88 questões\n",
            "Obstetrícia: 87 questões\n",
            "Endocrinologia: 78 questões\n",
            "Oncologia: 70 questões\n",
            "Preventiva/Saúde Coletiva: 65 questões\n",
            "Neurologia: 59 questões\n",
            "Pneumologia: 49 questões\n",
            "Hematologia: 47 questões\n",
            "Saúde Coletiva: 38 questões\n",
            "Dermatologia: 38 questões\n",
            "Cardiologia: 37 questões\n",
            "Psiquiatria: 31 questões\n",
            "Ortopedia: 30 questões\n",
            "Nefrologia: 28 questões\n",
            "Urologia: 24 questões\n",
            "Neonatologia: 24 questões\n",
            "Geriatria: 23 questões\n",
            "Reumatologia: 19 questões\n",
            "Ética Médica: 14 questões\n",
            "Medicina Preventiva: 14 questões\n",
            "Medicina Legal: 13 questões\n",
            "Oftalmologia: 12 questões\n",
            "Saúde do Trabalhador: 10 questões\n",
            "Imunologia: 9 questões\n",
            "Medicina de Família e Comunidade: 9 questões\n",
            "Epidemiologia: 9 questões\n",
            "Toxicologia: 8 questões\n",
            "Saúde Pública: 8 questões\n",
            "Clínica Médica: 8 questões\n",
            "Otorrinolaringologia: 7 questões\n",
            "Proctologia: 7 questões\n",
            "Genética: 6 questões\n",
            "Cirurgia Pediátrica: 6 questões\n",
            "Radiologia: 6 questões\n",
            "Administração em Saúde: 6 questões\n",
            "Neurocirurgia: 5 questões\n",
            "Hepatologia: 5 questões\n",
            "Angiologia: 5 questões\n",
            "Cirurgia Vascular: 5 questões\n",
            "Mastologia: 5 questões\n",
            "Medicina Preventiva/Saúde Coletiva: 5 questões\n",
            "Hipertensão: 4 questões\n",
            "Nutrição: 4 questões\n",
            "Anestesiologia: 3 questões\n",
            "Atenção Primária: 2 questões\n",
            "Genética Médica: 2 questões\n",
            "Saúde da Família: 2 questões\n",
            "Trauma: 2 questões\n",
            "Queimaduras: 1 questões\n",
            "Imunohematologia: 1 questões\n",
            "Coloproctologia: 1 questões\n",
            "Cirurgia de Cabeça e Pescoço: 1 questões\n",
            "Saúde Indígena: 1 questões\n",
            "Medicina da Família e Comunidade: 1 questões\n",
            "Saúde da Mulher: 1 questões\n",
            "Legislação: 1 questões\n",
            "Medicina Integrativa: 1 questões\n",
            "Nutricão: 1 questões\n",
            "Odontologia: 1 questões\n",
            "Medicina Tropical: 1 questões\n",
            "Ultrassonografia: 1 questões\n",
            "Psiquiatri: 1 questões\n",
            "Citogenética: 1 questões\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Resumo: Esse script le um arquivo JSON com perguntas de vestibular de Medicina,\n",
        "envia para uma IA classificar as perguntas dentro de áreas da medicina,\n",
        "e por fim, gera um novo JSON com as perguntas classificadas, para podermos\n",
        "filtrar e agrupar por áreas médicas\n",
        "\n",
        "Autor: Daniel Talon\n",
        "Data: Abril 2025\n",
        "'''\n",
        "\n",
        "# --- PASSO 1: Instalar a biblioteca ---\n",
        "%pip install -q -U google-generativeai\n",
        "\n",
        "# --- PASSO 2: Importações ---\n",
        "import json\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import ast\n",
        "from collections import Counter\n",
        "import os\n",
        "from google.api_core import exceptions as google_api_exceptions\n",
        "import requests\n",
        "import math\n",
        "\n",
        "# ==============================================================================\n",
        "# --- BLOCO DE CONFIGURAÇÃO ---\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Parâmetros de Execução ---\n",
        "\n",
        "# ANOS A PROCESSAR: Coloque os anos desejados em uma lista.\n",
        "# Exemplo: [2024] para processar apenas 2024\n",
        "# Exemplo: [2023, 2024] para processar 2023 e 2024\n",
        "# Exemplo: [] para processar TODOS os anos (cuidado com a quota da API!)\n",
        "TARGET_YEARS = [2024,2023,2022,2021] # <<< MODIFIQUE AQUI OS ANOS DESEJADOS\n",
        "\n",
        "# MÁXIMO DE QUESTÕES A PROCESSAR: Limita o número total de questões enviadas à API.\n",
        "# Útil para testes. Defina como None ou <= 0 para processar todas as questões filtradas.\n",
        "MAX_QUESTIONS_TO_PROCESS = 700 # <<< MODIFIQUE AQUI PARA TESTAR (ex: 10, 50, ou None)\n",
        "\n",
        "# TAMANHO DO LOTE: Questões por chamada de API.\n",
        "# Valores menores (ex: 10-25) são mais seguros contra erros de contexto/parse da IA.\n",
        "# Valores maiores reduzem o número de chamadas, mas aumentam o risco de erros.\n",
        "BATCH_SIZE = 25 # <<< AJUSTE SE NECESSÁRIO\n",
        "\n",
        "# PAUSA ENTRE LOTES: Tempo (segundos) de espera entre lotes. Aumente se receber erro 429.\n",
        "# 5 segundos = ~12 chamadas/min; 10 segundos = ~6 chamadas/min\n",
        "PAUSA_ENTRE_LOTES = 6 # <<< AJUSTE SE NECESSÁRIO (em segundos)\n",
        "\n",
        "# MÁXIMO DE TENTATIVAS POR LOTE: Em caso de erro de conexão/API.\n",
        "MAX_TENTATIVAS_LOTE = 3\n",
        "\n",
        "# --- Configurações da API e Modelo ---\n",
        "API_KEY_SECRET_NAME = 'GOOGLE_API_KEY' # Nome do segredo no Colab\n",
        "MODEL_NAME = 'gemini-1.5-flash'       # Modelo Gemini a ser usado\n",
        "OUTPUT_FILE_NAME_SUFFIX = '_classificadas_lote.json' # Sufixo para o nome do arquivo de saída\n",
        "\n",
        "# Configurações de geração da IA\n",
        "GENERATION_CONFIG = genai.GenerationConfig(\n",
        "    temperature=0.2,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    # max_output_tokens=8192, # Descomente e ajuste se necessário para lotes maiores\n",
        "    response_mime_type=\"application/json\" # Solicita explicitamente saída JSON\n",
        ")\n",
        "\n",
        "# Configurações de segurança da IA\n",
        "SAFETY_SETTINGS = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
        "]\n",
        "\n",
        "# --- Caminhos dos Arquivos ---\n",
        "INPUT_FILE_PATH = '/content/questoes-Revalida+Fuvest.json'\n",
        "# Gera nome do arquivo de saída baseado nos anos ou 'todos' e no limite\n",
        "years_str = \"_\".join(map(str, sorted(TARGET_YEARS))) if TARGET_YEARS else \"todos_anos\"\n",
        "limit_str = f\"_limit{MAX_QUESTIONS_TO_PROCESS}\" if (MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0) else \"\"\n",
        "OUTPUT_FILE_PATH = f'/content/questoes_{years_str}{limit_str}{OUTPUT_FILE_NAME_SUFFIX}'\n",
        "\n",
        "# ==============================================================================\n",
        "# --- FIM DO BLOCO DE CONFIGURAÇÃO ---\n",
        "# ==============================================================================\n",
        "\n",
        "# --- Configuração da API Key ---\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get(API_KEY_SECRET_NAME)\n",
        "    if not GOOGLE_API_KEY:\n",
        "        raise ValueError(\"API Key não encontrada ou vazia.\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    print(\"API Key carregada com sucesso.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar a API Key '{API_KEY_SECRET_NAME}': {e}\")\n",
        "    print(\"Por favor, certifique-se de que adicionou a chave aos Secrets do Colab e ativou o 'Notebook access'.\")\n",
        "    raise SystemExit(\"API Key não configurada.\")\n",
        "\n",
        "# --- Configuração do Modelo ---\n",
        "try:\n",
        "    model = genai.GenerativeModel(MODEL_NAME)\n",
        "    print(f\"Modelo Gemini '{MODEL_NAME}' configurado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar o modelo Gemini '{MODEL_NAME}': {e}\")\n",
        "    raise SystemExit(\"Falha na configuração do modelo.\")\n",
        "\n",
        "# --- Leitura do JSON de Entrada ---\n",
        "all_data = []\n",
        "print(f\"\\nTentando ler o arquivo de entrada: {INPUT_FILE_PATH}\")\n",
        "if not os.path.exists(INPUT_FILE_PATH):\n",
        "    print(f\"Erro: Arquivo '{INPUT_FILE_PATH}' não encontrado.\")\n",
        "    print(\"Certifique-se de que o arquivo foi carregado corretamente no Colab.\")\n",
        "else:\n",
        "    try:\n",
        "        with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
        "            all_data = json.load(f)\n",
        "        print(f\"Arquivo '{INPUT_FILE_PATH}' lido com sucesso. {len(all_data)} questões encontradas no total.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Erro: O arquivo '{INPUT_FILE_PATH}' não é um JSON válido.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro inesperado ao ler o arquivo: {e}\")\n",
        "\n",
        "# --- Filtragem e Limitação dos Dados ---\n",
        "data_to_process = []\n",
        "if all_data:\n",
        "    # Filtra por ano\n",
        "    if TARGET_YEARS:\n",
        "        data_filtered_by_year = [q for q in all_data if q.get('prova') in TARGET_YEARS]\n",
        "        years_str_msg = \", \".join(map(str, TARGET_YEARS))\n",
        "        print(f\"\\nFiltrado para o(s) ano(s): {years_str_msg}. {len(data_filtered_by_year)} questões encontradas.\")\n",
        "    else:\n",
        "        data_filtered_by_year = all_data\n",
        "        print(\"\\nNenhum ano específico selecionado. Considerando todas as questões.\")\n",
        "\n",
        "    # Aplica o limite máximo\n",
        "    if MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0:\n",
        "        if len(data_filtered_by_year) > MAX_QUESTIONS_TO_PROCESS:\n",
        "            print(f\"Limitando o processamento às primeiras {MAX_QUESTIONS_TO_PROCESS} questões filtradas.\")\n",
        "            data_to_process = data_filtered_by_year[:MAX_QUESTIONS_TO_PROCESS]\n",
        "        else:\n",
        "            print(f\"Número de questões filtradas ({len(data_filtered_by_year)}) é menor ou igual ao limite ({MAX_QUESTIONS_TO_PROCESS}). Processando todas as filtradas.\")\n",
        "            data_to_process = data_filtered_by_year\n",
        "    else:\n",
        "        print(\"Nenhum limite máximo de questões definido. Processando todas as questões filtradas.\")\n",
        "        data_to_process = data_filtered_by_year\n",
        "\n",
        "    if not data_to_process:\n",
        "         print(\"Nenhuma questão selecionada para processamento após filtros/limites.\")\n",
        "\n",
        "else:\n",
        "    print(\"Nenhum dado carregado do arquivo JSON.\")\n",
        "\n",
        "# --- Processamento em Lotes ---\n",
        "if data_to_process:\n",
        "    print(f\"\\nIniciando classificação de {len(data_to_process)} questões em lotes...\")\n",
        "    area_counter = Counter()\n",
        "    total_questoes_a_processar = len(data_to_process)\n",
        "    questoes_processadas_sucesso = 0\n",
        "    erros_api_lote = 0\n",
        "    erros_parse_lote = 0\n",
        "    questoes_nao_retornadas_no_lote = 0\n",
        "\n",
        "    num_lotes = math.ceil(total_questoes_a_processar / BATCH_SIZE)\n",
        "    print(f\"Processando em {num_lotes} lotes de até {BATCH_SIZE} questões cada.\")\n",
        "\n",
        "    for i in range(0, total_questoes_a_processar, BATCH_SIZE):\n",
        "        lote_questoes = data_to_process[i : i + BATCH_SIZE] # Pega o slice correto dos dados a processar\n",
        "        lote_numero = (i // BATCH_SIZE) + 1\n",
        "        print(f\"\\nProcessando Lote {lote_numero}/{num_lotes} (Questões {i+1} a {min(i+BATCH_SIZE, total_questoes_a_processar)})...\")\n",
        "\n",
        "        # Construir o prompt para o lote\n",
        "        prompt_lote = \"\"\"\n",
        "        Analise os enunciados das questões médicas abaixo, identificadas por 'ID: [Prova]-[Numero]'.\n",
        "        Para CADA questão, classifique-a em uma ou mais áreas principais da medicina (exemplos: Pediatria, Obstetrícia, Ginecologia, Cardiologia, Cirurgia Geral, Clínica Médica, Preventiva/Saúde Coletiva, Infectologia, Psiquiatria, Dermatologia, Neurologia, Ortopedia, Oftalmologia, Otorrinolaringologia, Nefrologia, Endocrinologia, Gastroenterologia, Pneumologia, Hematologia, Oncologia, Ética Médica, Medicina Legal, Saúde do Trabalhador, Geriatria, Urgência/Emergência).\n",
        "        Se uma questão abordar múltiplos temas, liste todas as áreas relevantes. Se for muito geral, use 'Clínica Médica Geral'.\n",
        "\n",
        "        Retorne sua resposta ESTRITAMENTE como um único dicionário JSON válido, onde as chaves são os 'ID' das questões (no formato 'Prova-Numero') e os valores são listas de strings contendo as áreas médicas identificadas para aquela questão específica. Garanta que o JSON esteja completo e bem formatado.\n",
        "\n",
        "        Exemplo de formato de saída JSON esperado:\n",
        "        {\n",
        "          \"2011-1\": [\"Endocrinologia\", \"Gastroenterologia\", \"Clínica Médica Geral\"],\n",
        "          \"2011-2\": [\"Pediatria\", \"Hematologia\", \"Oncologia\", \"Infectologia\"]\n",
        "        }\n",
        "\n",
        "        Questões para classificar:\n",
        "        \"\"\"\n",
        "        ids_no_lote = []\n",
        "        # Itera sobre o lote atual para construir o prompt\n",
        "        for q_idx_lote, questao_lote in enumerate(lote_questoes):\n",
        "            # Usa o índice global (i + q_idx_lote) para gerar ID único se 'numero' faltar\n",
        "            prova = questao_lote.get('prova', 'PNA')\n",
        "            numero = questao_lote.get('numero', f'idx{i+q_idx_lote+1}')\n",
        "            enunciado = questao_lote.get('enunciado', '')\n",
        "            q_id = f\"{prova}-{numero}\"\n",
        "            ids_no_lote.append(q_id)\n",
        "            prompt_lote += f\"\\n\\nID: {q_id}\\nEnunciado: {enunciado}\\n---\"\n",
        "\n",
        "        prompt_lote += \"\\n\\nDicionário JSON com as classificações:\"\n",
        "\n",
        "        # Chamar a API para o lote com retentativas\n",
        "        tentativa_atual = 0\n",
        "        sucesso_lote = False\n",
        "        response_lote = None\n",
        "\n",
        "        while tentativa_atual < MAX_TENTATIVAS_LOTE and not sucesso_lote:\n",
        "            tentativa_atual += 1\n",
        "            try:\n",
        "                response_lote = model.generate_content(\n",
        "                    prompt_lote,\n",
        "                    generation_config=GENERATION_CONFIG,\n",
        "                    safety_settings=SAFETY_SETTINGS\n",
        "                )\n",
        "                sucesso_lote = True\n",
        "\n",
        "            except google_api_exceptions.ResourceExhausted as e:\n",
        "                print(f\"  [ERRO API Lote {lote_numero} - Tentativa {tentativa_atual}/{MAX_TENTATIVAS_LOTE}: Quota Excedida (429). Esperando {PAUSA_ENTRE_LOTES * 5}s...]\")\n",
        "                time.sleep(PAUSA_ENTRE_LOTES * 5)\n",
        "            except (requests.exceptions.ConnectionError, google_api_exceptions.ServiceUnavailable, ConnectionResetError, google_api_exceptions.InternalServerError) as e:\n",
        "                print(f\"  [ERRO API Lote {lote_numero} - Tentativa {tentativa_atual}/{MAX_TENTATIVAS_LOTE}: Erro de conexão/servidor ({type(e).__name__}). Esperando {PAUSA_ENTRE_LOTES}s...]\")\n",
        "                time.sleep(PAUSA_ENTRE_LOTES)\n",
        "            except google_api_exceptions.InvalidArgument as e:\n",
        "                 print(f\"  [ERRO API Lote {lote_numero} - Tentativa {tentativa_atual}/{MAX_TENTATIVAS_LOTE}: Argumento Inválido (400). Pode ser limite de contexto. Erro: {e}]\")\n",
        "                 sucesso_lote = True # Sai do loop, erro provavelmente não recuperável\n",
        "                 response_lote = None # Garante que não tentará processar resposta inválida\n",
        "            except Exception as e:\n",
        "                print(f\"  [ERRO GERAL INESPERADO Lote {lote_numero} - Tentativa {tentativa_atual}/{MAX_TENTATIVAS_LOTE}: {type(e).__name__} - {e}]\")\n",
        "                sucesso_lote = True # Sai do loop\n",
        "                response_lote = None # Garante que não tentará processar resposta inválida\n",
        "                time.sleep(PAUSA_ENTRE_LOTES * 2)\n",
        "\n",
        "        # Processar a resposta do lote\n",
        "        if sucesso_lote and response_lote:\n",
        "            classificacoes_lote_dict = {}\n",
        "            texto_resposta_limpo = \"\"\n",
        "            try:\n",
        "                if response_lote.parts:\n",
        "                    texto_resposta = response_lote.text.strip()\n",
        "                    # Limpeza básica de markdown\n",
        "                    if texto_resposta.startswith(\"```json\"):\n",
        "                        texto_resposta = texto_resposta[len(\"```json\"):].strip()\n",
        "                    elif texto_resposta.startswith(\"```\"):\n",
        "                        texto_resposta = texto_resposta[len(\"```\"):].strip()\n",
        "                    if texto_resposta.endswith(\"```\"):\n",
        "                        texto_resposta = texto_resposta[:-len(\"```\")].strip()\n",
        "                    texto_resposta_limpo = texto_resposta\n",
        "\n",
        "                    classificacoes_lote_dict = json.loads(texto_resposta_limpo)\n",
        "\n",
        "                    if not isinstance(classificacoes_lote_dict, dict):\n",
        "                         raise TypeError(\"Resposta da IA não é um dicionário JSON.\")\n",
        "\n",
        "                    # Atualizar as questões no 'data_to_process'\n",
        "                    # Itera sobre o lote original para atualizar os dicionários corretos\n",
        "                    for q_idx_lote, questao_original in enumerate(lote_questoes):\n",
        "                        prova = questao_original.get('prova', 'PNA')\n",
        "                        numero = questao_original.get('numero', f'idx{i+q_idx_lote+1}')\n",
        "                        q_id = f\"{prova}-{numero}\"\n",
        "\n",
        "                        if q_id in classificacoes_lote_dict:\n",
        "                            areas = classificacoes_lote_dict[q_id]\n",
        "                            if isinstance(areas, list) and all(isinstance(item, str) for item in areas):\n",
        "                                # Atualiza o dicionário original na lista data_to_process\n",
        "                                questao_original['areas_medicas'] = [area.strip() for area in areas if area.strip()] or ['Não Classificado - Lista Vazia']\n",
        "                                area_counter.update(questao_original['areas_medicas'])\n",
        "                                questoes_processadas_sucesso += 1\n",
        "                            else:\n",
        "                                print(f\"  [AVISO Lote {lote_numero}: Formato inválido para ID {q_id}. Valor: {areas}]\")\n",
        "                                questao_original['areas_medicas'] = ['Não Classificado - Formato Inválido']\n",
        "                                erros_parse_lote += 1\n",
        "                        else:\n",
        "                            print(f\"  [AVISO Lote {lote_numero}: ID {q_id} não encontrado na resposta da IA.]\")\n",
        "                            questao_original['areas_medicas'] = ['Não Classificado - ID Ausente']\n",
        "                            questoes_nao_retornadas_no_lote += 1\n",
        "                else:\n",
        "                    # Tratamento para resposta bloqueada ou vazia\n",
        "                    block_reason = response_lote.prompt_feedback.block_reason if response_lote.prompt_feedback else \"Razão desconhecida\"\n",
        "                    print(f\"  [AVISO Lote {lote_numero}: Resposta vazia ou bloqueada pela IA. Razão: {block_reason}]\")\n",
        "                    for q in lote_questoes: q['areas_medicas'] = ['Não Classificado - Lote Bloqueado']\n",
        "                    erros_api_lote += len(lote_questoes)\n",
        "\n",
        "            except (json.JSONDecodeError, TypeError) as parse_error:\n",
        "                print(f\"  [ERRO ao parsear JSON do Lote {lote_numero}: {parse_error}. Resposta recebida (após limpeza): '{texto_resposta_limpo}']\")\n",
        "                for q in lote_questoes: q['areas_medicas'] = ['Não Classificado - Erro Parse Lote']\n",
        "                erros_parse_lote += len(lote_questoes)\n",
        "            except Exception as e:\n",
        "                print(f\"  [ERRO inesperado ao processar resposta do Lote {lote_numero}: {e}]\")\n",
        "                for q in lote_questoes: q['areas_medicas'] = ['Não Classificado - Erro Inesperado Lote']\n",
        "                erros_parse_lote += len(lote_questoes)\n",
        "\n",
        "        elif not sucesso_lote: # Se falhou após todas as tentativas\n",
        "            print(f\"  [ERRO API Lote {lote_numero}: Falha ao obter resposta após {MAX_TENTATIVAS_LOTE} tentativas.]\")\n",
        "            for q in lote_questoes: q['areas_medicas'] = ['Erro API - Lote Falhou']\n",
        "            erros_api_lote += len(lote_questoes)\n",
        "\n",
        "        # Pausa entre lotes, independentemente do sucesso ou falha do lote\n",
        "        print(f\"  Lote {lote_numero} concluído. Pausando por {PAUSA_ENTRE_LOTES} segundos...\")\n",
        "        time.sleep(PAUSA_ENTRE_LOTES)\n",
        "\n",
        "    # --- PASSO 5: Salvar o Novo JSON (APENAS os dados processados) ---\n",
        "    print(f\"\\nSalvando os resultados classificados em: {OUTPUT_FILE_PATH}\")\n",
        "    try:\n",
        "        # Salva a lista 'data_to_process' que contém apenas as questões que foram selecionadas e processadas\n",
        "        with open(OUTPUT_FILE_PATH, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data_to_process, f, ensure_ascii=False, indent=4)\n",
        "        print(\"Arquivo salvo com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao salvar o arquivo JSON de saída: {e}\")\n",
        "\n",
        "    # --- PASSO 6: Gerar Resumo ---\n",
        "    print(\"\\n--- Resumo da Classificação por Área ---\")\n",
        "    years_str_msg = \", \".join(map(str, TARGET_YEARS)) if TARGET_YEARS else \"Todos os anos\"\n",
        "    limit_msg = f\"(limitado a {MAX_QUESTIONS_TO_PROCESS})\" if (MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0) else \"\"\n",
        "    print(f\"Anos processados: {years_str_msg} {limit_msg}\")\n",
        "    print(f\"Total de questões processadas: {total_questoes_a_processar}\")\n",
        "    print(f\"Questões classificadas com sucesso: {questoes_processadas_sucesso}\")\n",
        "    print(f\"Questões com erro na chamada da API (Quota/Conexão/Outros): {erros_api_lote}\")\n",
        "    print(f\"Questões com erro no parse da resposta da IA: {erros_parse_lote}\")\n",
        "    print(f\"Questões não retornadas pela IA dentro de um lote: {questoes_nao_retornadas_no_lote}\")\n",
        "    print(\"-\" * 20)\n",
        "    if area_counter:\n",
        "        # Exclui categorias de erro/não classificação do resumo principal\n",
        "        areas_validas = {k: v for k, v in area_counter.items() if not k.startswith('Erro') and not k.startswith('Não Classificado')}\n",
        "        if areas_validas:\n",
        "             print(\"Contagem por área (excluindo erros/não classificados):\")\n",
        "             for area, contagem in Counter(areas_validas).most_common():\n",
        "                 print(f\"{area}: {contagem} questões\")\n",
        "        else:\n",
        "             print(\"Nenhuma área válida foi classificada.\")\n",
        "    else:\n",
        "        print(\"Nenhuma classificação foi realizada com sucesso.\")\n",
        "\n",
        "elif not all_data:\n",
        "     print(\"\\nNenhum dado foi carregado do arquivo JSON. Classificação e salvamento cancelados.\")\n",
        "elif not data_to_process:\n",
        "     print(\"\\nNenhuma questão selecionada para processamento após filtros/limites.\")"
      ]
    }
  ]
}