{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1y0XJCllIzY4IiH7FbqM9DteoO6yLDRc0",
      "authorship_tag": "ABX9TyNbA8rp6DJntgMai5lTH7c2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieltalon/trabalho_RAG/blob/main/trabalho_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "FXAwu_Mz1flc",
        "outputId": "7d9c2f41-97c3-4246-ddc2-d1b8ea346b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.1/434.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, google-ai-generativelanguage, langchain-google-genai, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.23\n",
            "    Uninstalling langchain-0.3.23:\n",
            "      Successfully uninstalled langchain-0.3.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.17 httpx-sse-0.4.0 langchain-0.3.24 langchain-community-0.3.22 langchain-core-0.3.55 langchain-google-genai-2.1.3 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "fde294be4857400db66587b4586d380f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Bibliotecas instaladas.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain langchain-community langchain-google-genai\n",
        "%pip install pypdf sentence-transformers faiss-cpu tiktoken python-dotenv\n",
        "print(\"Bibliotecas instaladas.\")\n",
        "\n",
        "# pra que serve o \"-q\" no pip install?\n",
        "# Se for usar LlamaCpp (alternativa ao Gemini):\n",
        "# !pip install llama-cpp-python -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from google.colab import userdata, drive # Para secrets e Google Drive\n",
        "import torch # Para verificar GPU\n",
        "import pandas as pd\n",
        "from IPython.display import display # Para mostrar tabelas\n",
        "\n",
        "# Langchain e componentes relacionados\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Usando Gemini\n",
        "# from langchain_community.chat_models import ChatOllama # Alternativa Ollama\n",
        "# from langchain_community.llms import LlamaCpp # Alternativa LlamaCpp\n",
        "\n",
        "# Ignorar avisos específicos se necessário (opcional)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "Kt8C4L1GzMNy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configurações ---\n",
        "\n",
        "# 1. Montar Google Drive (Recomendado para persistência)\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_MOUNTED = True\n",
        "    # Defina um caminho base no seu Google Drive\n",
        "    BASE_DRIVE_PATH = \"/content/drive/MyDrive/RAG/\" # <--- AJUSTE SE NECESSÁRIO\n",
        "    os.makedirs(BASE_DRIVE_PATH, exist_ok=True)\n",
        "    print(f\"Google Drive montado em /content/drive. Usando base: {BASE_DRIVE_PATH}\")\n",
        "except Exception as e:\n",
        "    DRIVE_MOUNTED = False\n",
        "    BASE_DRIVE_PATH = \"/content/\" # Usar armazenamento local temporário do Colab\n",
        "    print(f\"Google Drive não montado ou erro: {e}. Usando armazenamento local temporário: {BASE_DRIVE_PATH}\")\n",
        "    print(\"AVISO: O índice vetorial NÃO será salvo permanentemente.\")\n",
        "\n",
        "# 2. Caminhos para os arquivos (ajuste conforme onde você colocou os arquivos)\n",
        "#    Coloque seu PDF e perguntas.txt na pasta BASE_DRIVE_PATH no seu Google Drive\n",
        "#    OU faça upload manual para /content/ no Colab (mas serão perdidos ao desconectar)\n",
        "PDF_PATH = os.path.join(BASE_DRIVE_PATH, \"saude_coletiva.pdf\")\n",
        "QUESTIONS_PATH = os.path.join(BASE_DRIVE_PATH, \"perguntas.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVwq7Ge52ASz",
        "outputId": "2533ae12-4eb9-4799-9b3f-fa606fcafd4f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado em /content/drive. Usando base: /content/drive/MyDrive/RAG/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Definição das Configurações de RAG para Comparar ---\n",
        "\n",
        "# Configuração A: MiniLM Embeddings, Chunks Maiores, k=4\n",
        "config_A = {\n",
        "    \"name\": \"MiniLM_LargeChunks_k4\",\n",
        "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"chunk_size\": 1500,\n",
        "    \"chunk_overlap\": 300,\n",
        "    \"k_retrieval\": 4,\n",
        "    \"vector_store_path\": os.path.join(BASE_DRIVE_PATH, \"faiss_index_config_A\"),\n",
        "    \"llm_provider\": \"gemini\", # Manter o mesmo LLM para comparar o retrieval/embedding\n",
        "    \"llm_model\": \"gemini-1.5-flash-latest\"\n",
        "}\n",
        "\n",
        "# Configuração B: MPNet Embeddings (melhor qualidade), Chunks Menores, k=5\n",
        "config_B = {\n",
        "    #\"name\": \"MPNet_SmallChunks_k5\",\n",
        "    #\"embedding_model\": \"sentence-transformers/all-mpnet-base-v2\", # Modelo diferente\n",
        "    \"name\": \"QA-MiniLM_SmallChunks_k5\", # Atualize o nome para refletir a mudança\n",
        "    \"embedding_model\": \"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\", # <--- MODELO ALTERADO AQUI\n",
        "    \"chunk_size\": 800, # Tamanho diferente\n",
        "    \"chunk_overlap\": 150, # Overlap diferente\n",
        "    \"k_retrieval\": 5, # k diferente\n",
        "    \"vector_store_path\": os.path.join(BASE_DRIVE_PATH, \"faiss_index_config_B\"), # Caminho DIFERENTE\n",
        "    \"llm_provider\": \"gemini\", # Mesmo LLM\n",
        "    \"llm_model\": \"gemini-1.5-flash-latest\"\n",
        "}\n",
        "\n",
        "# Lista de configurações a serem testadas\n",
        "configurations = [config_A, config_B]\n",
        "\n",
        "# Carregar API Key do Gemini (apenas uma vez se ambas usarem Gemini)\n",
        "# Coloque isso fora das configs se for o mesmo para todas\n",
        "LLM_REQUIRES_API_KEY = any(conf.get(\"llm_provider\") == \"gemini\" for conf in configurations)\n",
        "if LLM_REQUIRES_API_KEY:\n",
        "    try:\n",
        "        GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "        if not GOOGLE_API_KEY:\n",
        "            raise ValueError(\"Secret 'GOOGLE_API_KEY' não encontrado ou vazio.\")\n",
        "        os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "        print(\"API Key do Google carregada via Colab Secrets.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar GOOGLE_API_KEY: {e}\")\n",
        "        raise SystemExit(\"Chave API do Google não configurada.\")\n",
        "\n",
        "\n",
        "# --- Escolha e Configuração do LLM ---\n",
        "##LLM_PROVIDER = \"gemini\" # Ou \"ollama\", \"llamacpp\"\n",
        "\n",
        "# Configuração específica do Gemini\n",
        "#if LLM_PROVIDER == \"gemini\":\n",
        "#    try:\n",
        "        # Use o gerenciador de Secrets do Colab (ícone de chave na barra esquerda)\n",
        "        # Adicione um secret chamado 'GOOGLE_API_KEY' com sua chave API do Google AI Studio\n",
        "#        GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "#        if not GOOGLE_API_KEY:\n",
        "#            raise ValueError(\"Secret 'GOOGLE_API_KEY' não encontrado ou vazio.\")\n",
        "#        os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
        "#        GEMINI_MODEL = \"gemini-1.5-flash-latest\" # Modelo Gemini rápido e eficiente\n",
        "#        print(\"API Key do Google carregada via Colab Secrets.\")\n",
        "#    except Exception as e:\n",
        "#        print(f\"Erro ao carregar GOOGLE_API_KEY do Colab Secrets: {e}\")\n",
        "#        print(\"Por favor, adicione sua chave API do Google AI Studio como um Secret chamado 'GOOGLE_API_KEY' no Colab.\")\n",
        "        # Interrompe a execução se a chave não for encontrada\n",
        "#        raise SystemExit(\"Chave API do Google não configurada.\")\n",
        "\n",
        "# Configuração alternativa (Ollama - requer Ollama rodando em algum lugar acessível)\n",
        "# elif LLM_PROVIDER == \"ollama\":\n",
        "#     OLLAMA_BASE_URL = \"http://localhost:11434\" # Se rodando localmente e usando ngrok/proxy para expor ao Colab\n",
        "#     OLLAMA_MODEL = \"mistral\" # Modelo rodando no Ollama\n",
        "#     print(f\"Configurado para usar Ollama em {OLLAMA_BASE_URL} com modelo {OLLAMA_MODEL}\")\n",
        "\n",
        "# Configuração alternativa (LlamaCpp - requer download do modelo GGUF)\n",
        "# elif LLM_PROVIDER == \"llamacpp\":\n",
        "#     # Faça upload do seu modelo .gguf para o Drive ou Colab\n",
        "#     LLAMA_CPP_MODEL_PATH = os.path.join(BASE_DRIVE_PATH, \"seu_modelo.gguf\") # <--- AJUSTE O NOME DO ARQUIVO\n",
        "#     print(f\"Configurado para usar LlamaCpp com modelo em: {LLAMA_CPP_MODEL_PATH}\")\n",
        "#     if not os.path.exists(LLAMA_CPP_MODEL_PATH):\n",
        "#         print(f\"AVISO: Modelo LlamaCpp não encontrado em {LLAMA_CPP_MODEL_PATH}\")\n",
        "#         # Poderia tentar baixar aqui se tiver URL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzHedGG_7KIN",
        "outputId": "2507299b-32c5-4588-bfc0-c42a0e3a4292"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key do Google carregada via Colab Secrets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Verificar disponibilidade de GPU\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda'\n",
        "    print(\"GPU detectada! Usando CUDA.\")\n",
        "else:\n",
        "    DEVICE = 'cpu'\n",
        "    print(\"GPU não detectada ou não configurada. Usando CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRsEjR8h7aaV",
        "outputId": "6dc0069c-4223-424e-df5a-e8e4be461b48"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU não detectada ou não configurada. Usando CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_docs(pdf_path):\n",
        "    \"\"\"Carrega o documento PDF.\"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "         raise FileNotFoundError(f\"Arquivo PDF não encontrado em: {pdf_path}. Verifique o upload ou o caminho no Drive.\")\n",
        "    print(f\"Carregando PDF de: {pdf_path}\")\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    documents = loader.load()\n",
        "    print(f\"PDF carregado. Número de páginas/documentos iniciais: {len(documents)}\")\n",
        "    return documents\n",
        "\n",
        "def split_docs_into_chunks(docs, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"Divide os documentos carregados em chunks menores.\"\"\"\n",
        "    print(f\"Dividindo documentos em chunks (tamanho: {chunk_size}, sobreposição: {chunk_overlap})\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "        length_function=len,\n",
        "        add_start_index=True,\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(docs)\n",
        "    print(f\"Número de chunks criados: {len(chunks)}\")\n",
        "    return chunks\n",
        "\n",
        "def get_embedding_model(model_name, device):\n",
        "    \"\"\"Retorna o modelo de embedding HuggingFace especificado.\"\"\"\n",
        "    print(f\"Carregando embeddings HuggingFace: {model_name} no dispositivo: {device}\")\n",
        "    try:\n",
        "        model_kwargs = {'device': device}\n",
        "        encode_kwargs = {'normalize_embeddings': False}\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=model_name,\n",
        "            model_kwargs=model_kwargs,\n",
        "            encode_kwargs=encode_kwargs\n",
        "        )\n",
        "        # embeddings.embed_query(\"Teste rápido\") # Opcional: Teste de carregamento\n",
        "        return embeddings\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Instale 'sentence-transformers': !pip install sentence-transformers\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar modelo de embedding {model_name}: {e}\")\n",
        "        raise\n",
        "\n",
        "def create_or_load_vector_store(chunks, embeddings, store_path):\n",
        "    \"\"\"Cria um novo vector store FAISS ou carrega um existente.\"\"\"\n",
        "    if os.path.exists(store_path):\n",
        "        print(f\"Carregando Vector Store FAISS existente de: {store_path}\")\n",
        "        try:\n",
        "            vector_store = FAISS.load_local(store_path, embeddings, allow_dangerous_deserialization=True)\n",
        "            print(\"Vector Store carregado com sucesso.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar Vector Store: {e}. Tentando recriar...\")\n",
        "            os.remove(store_path) # Remove o índice potencialmente corrompido/incompatível\n",
        "            vector_store = create_new_vector_store(chunks, embeddings, store_path)\n",
        "    else:\n",
        "        vector_store = create_new_vector_store(chunks, embeddings, store_path)\n",
        "    return vector_store\n",
        "\n",
        "def create_new_vector_store(chunks, embeddings, store_path):\n",
        "    \"\"\"Cria e salva um novo vector store FAISS.\"\"\"\n",
        "    print(\"Criando novo Vector Store FAISS...\")\n",
        "    start_time = time.time()\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    end_time = time.time()\n",
        "    print(f\"Vector Store criado em {end_time - start_time:.2f} segundos.\")\n",
        "    print(f\"Salvando Vector Store em: {store_path}\")\n",
        "    vector_store.save_local(store_path)\n",
        "    print(\"Vector Store salvo.\")\n",
        "    return vector_store\n",
        "\n",
        "\n",
        "def load_questions(questions_path):\n",
        "    \"\"\"Carrega as perguntas do arquivo de texto.\"\"\"\n",
        "    if not os.path.exists(questions_path):\n",
        "         raise FileNotFoundError(f\"Arquivo de perguntas não encontrado em: {questions_path}. Verifique o upload ou o caminho no Drive.\")\n",
        "    print(f\"Carregando perguntas de: {questions_path}\")\n",
        "    try:\n",
        "        with open(questions_path, 'r', encoding='utf-8') as f:\n",
        "            questions = [line.strip() for line in f if line.strip()]\n",
        "        print(f\"Carregadas {len(questions)} perguntas.\")\n",
        "        return questions\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler o arquivo de perguntas '{questions_path}': {e}\")\n",
        "        return []\n",
        "\n",
        "def get_llm(llm_config):\n",
        "    \"\"\"Retorna a instância do LLM com base na configuração fornecida.\"\"\"\n",
        "    provider = llm_config.get(\"llm_provider\")\n",
        "    model = llm_config.get(\"llm_model\")\n",
        "    print(f\"Configurando LLM Provider: {provider} com modelo: {model}\")\n",
        "\n",
        "    if provider == \"gemini\":\n",
        "        try:\n",
        "            # A chave API já deve estar no ambiente via Célula 2\n",
        "            if 'GOOGLE_API_KEY' not in os.environ:\n",
        "                 raise ValueError(\"Chave API do Google não encontrada no ambiente.\")\n",
        "            llm = ChatGoogleGenerativeAI(model=model,\n",
        "                                         temperature=0.3,\n",
        "                                         convert_system_message_to_human=True)\n",
        "            # llm.invoke(\"Olá!\") # Teste rápido\n",
        "            print(f\"Usando Google Gemini: {model}\")\n",
        "            return llm\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao instanciar ChatGoogleGenerativeAI: {e}\")\n",
        "            raise\n",
        "\n",
        "       # Adicione aqui blocos elif para outros providers (Ollama, LlamaCpp) se necessário,\n",
        "    # buscando os parâmetros relevantes de llm_config\n",
        "    # elif provider == \"ollama\":\n",
        "    #    ollama_model = llm_config.get(\"ollama_model\", \"mistral\") # Exemplo\n",
        "    #    ollama_base_url = llm_config.get(\"ollama_base_url\", \"http://localhost:11434\") # Exemplo\n",
        "    #    # ... código para instanciar ChatOllama ...\n",
        "    #    return llm\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Provedor LLM desconhecido ou não configurado: {provider}\")\n",
        "\n",
        "\n",
        "def setup_qa_chain(llm, vector_store, k_retrieval=5): # Definir k padrão aqui\n",
        "    \"\"\"Configura a cadeia de RetrievalQA.\"\"\"\n",
        "    print(f\"Configurando a cadeia de QA (RetrievalQA) para recuperar k={k_retrieval} chunks...\")\n",
        "    retriever = vector_store.as_retriever(search_kwargs={'k': k_retrieval}) # Usar k_retrieval\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        verbose=False\n",
        "    )\n",
        "    print(\"Cadeia de QA configurada.\")\n",
        "    return qa_chain\n",
        "\n",
        "def ask_questions(qa_chain, questions, vector_store, k_retrieval=5): # Adicionar vector_store e k_retrieval\n",
        "    \"\"\"Itera sobre as perguntas, obtém respostas e calcula score de relevância.\"\"\"\n",
        "    print(\"\\n--- Iniciando Sessão de Perguntas e Respostas ---\")\n",
        "    if not questions:\n",
        "        print(\"Nenhuma pergunta para processar.\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "    for i, question in enumerate(questions):\n",
        "        print(f\"\\n[Pergunta {i+1}/{len(questions)}]: {question}\")\n",
        "        start_time = time.time()\n",
        "        avg_relevance_score = 0.0\n",
        "        retrieved_docs_count = 0\n",
        "\n",
        "        try:\n",
        "            # 1. Obter a resposta do LLM via cadeia RAG\n",
        "            response = qa_chain.invoke({\"query\": question})\n",
        "            answer = response.get('result', 'Nenhuma resposta gerada.')\n",
        "            source_docs = response.get('source_documents', []) # Documentos usados pelo LLM\n",
        "            end_time = time.time()\n",
        "\n",
        "            # 2. Calcular o score de relevância médio dos chunks recuperados\n",
        "            #    Fazemos uma busca separada aqui para obter os scores de relevância normalizados\n",
        "            #    Idealmente, a cadeia retornaria isso, mas esta é uma forma prática.\n",
        "            #    Garante que estamos usando o mesmo k que a cadeia de QA.\n",
        "            if vector_store:\n",
        "                docs_with_scores = vector_store.similarity_search_with_relevance_scores(\n",
        "                    question, k=k_retrieval\n",
        "                )\n",
        "                retrieved_docs_count = len(docs_with_scores)\n",
        "                if docs_with_scores:\n",
        "                    scores = [score for doc, score in docs_with_scores]\n",
        "                    if scores:\n",
        "                        avg_relevance_score = sum(scores) / len(scores)\n",
        "\n",
        "            # 3. Imprimir resultados, incluindo o score\n",
        "            print(f\"[Resposta]: {answer}\")\n",
        "            print(f\"(Tempo: {end_time - start_time:.2f}s | Confiança Recuperação (Avg Score): {avg_relevance_score:.4f})\")\n",
        "            print(f\"  (Score médio de relevância dos {retrieved_docs_count} chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\")\n",
        "\n",
        "            results.append({\n",
        "                \"pergunta\": question,\n",
        "                \"resposta\": answer,\n",
        "                \"avg_relevance_score\": avg_relevance_score,\n",
        "                \"fontes\": source_docs # Mantém as fontes usadas pelo LLM\n",
        "            })\n",
        "\n",
        "            # Opcional: Mostrar trechos das fontes usadas (como antes)\n",
        "            # print(\"\\n[Fontes Utilizadas pelo LLM (Chunks)]:\")\n",
        "            # ... (código para mostrar fontes) ...\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar a pergunta: {e}\")\n",
        "            results.append({\n",
        "                \"pergunta\": question,\n",
        "                \"resposta\": f\"Erro: {e}\",\n",
        "                \"avg_relevance_score\": 0.0, # Score 0 em caso de erro\n",
        "                \"fontes\": []\n",
        "            })\n",
        "        finally:\n",
        "             print(\"-\" * 50)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "wMaIVqzg7gWL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Iniciando Comparação de Configurações RAG...\")\n",
        "\n",
        "# Carregar dados comuns uma vez\n",
        "try:\n",
        "    base_documents = load_pdf_docs(PDF_PATH)\n",
        "    questions = load_questions(QUESTIONS_PATH)\n",
        "    if not base_documents or not questions:\n",
        "        raise SystemExit(\"Erro ao carregar PDF ou perguntas. Verifique os arquivos.\")\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\"Erro na carga inicial: {e}\")\n",
        "\n",
        "# Armazenar resultados de todas as configurações\n",
        "all_results = {}\n",
        "\n",
        "# Iterar sobre cada configuração definida\n",
        "for config in configurations:\n",
        "    config_name = config[\"name\"]\n",
        "    print(f\"\\n===== Processando Configuração: {config_name} =====\")\n",
        "\n",
        "    try:\n",
        "        # 1. Chunking (específico da config)\n",
        "        chunks = split_docs_into_chunks(base_documents, config[\"chunk_size\"], config[\"chunk_overlap\"])\n",
        "        if not chunks:\n",
        "            print(f\"AVISO: Nenhum chunk gerado para {config_name}. Pulando esta config.\")\n",
        "            all_results[config_name] = [] # Armazena lista vazia para indicar falha/sem chunks\n",
        "            continue\n",
        "\n",
        "        # 2. Embedding (específico da config)\n",
        "        embeddings = get_embedding_model(config[\"embedding_model\"], DEVICE)\n",
        "\n",
        "        # 3. Vector Store (específico da config)\n",
        "        vector_store = create_or_load_vector_store(chunks, embeddings, config[\"vector_store_path\"])\n",
        "\n",
        "        # 4. LLM (específico da config)\n",
        "        llm = get_llm(config) # Passa a sub-configuração do LLM\n",
        "\n",
        "        # 5. QA Chain (específico da config)\n",
        "        qa_chain = setup_qa_chain(llm, vector_store, k_retrieval=config[\"k_retrieval\"])\n",
        "\n",
        "        # 6. Executar Perguntas\n",
        "        config_results = ask_questions(qa_chain, questions, vector_store, k_retrieval=config[\"k_retrieval\"])\n",
        "        all_results[config_name] = config_results # Armazena os resultados desta config\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERRO ao processar configuração {config_name}\")\n",
        "        print(f\"Erro: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        all_results[config_name] = [] # Armazena lista vazia para indicar falha\n",
        "\n",
        "    print(f\"===== Concluída Configuração: {config_name} =====\")\n",
        "\n",
        "##################################\n",
        "\n",
        "\n",
        "        # Opcional: Salvar resultados em um arquivo (útil no Colab)\n",
        "        # results_path = os.path.join(BASE_DRIVE_PATH, \"rag_results.txt\")\n",
        "        # print(f\"\\nSalvando resultados em: {results_path}\")\n",
        "        # with open(results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        #     for res in qa_results:\n",
        "        #         f.write(f\"Pergunta: {res['pergunta']}\\n\")\n",
        "        #         f.write(f\"Resposta: {res['resposta']}\\n\")\n",
        "        #         f.write(\"-\" * 20 + \"\\n\")\n",
        "        # print(\"Resultados salvos.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXj0AOJO_Ctk",
        "outputId": "0e2fc066-dd1d-4591-ccd7-755b47fc0a5d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando Comparação de Configurações RAG...\n",
            "Carregando PDF de: /content/drive/MyDrive/RAG/saude_coletiva.pdf\n",
            "PDF carregado. Número de páginas/documentos iniciais: 142\n",
            "Carregando perguntas de: /content/drive/MyDrive/RAG/perguntas.txt\n",
            "Carregadas 5 perguntas.\n",
            "\n",
            "===== Processando Configuração: MiniLM_LargeChunks_k4 =====\n",
            "Dividindo documentos em chunks (tamanho: 1500, sobreposição: 300)\n",
            "Número de chunks criados: 307\n",
            "Carregando embeddings HuggingFace: sentence-transformers/all-MiniLM-L6-v2 no dispositivo: cpu\n",
            "Carregando Vector Store FAISS existente de: /content/drive/MyDrive/RAG/faiss_index_config_A\n",
            "Vector Store carregado com sucesso.\n",
            "Configurando LLM Provider: gemini com modelo: gemini-1.5-flash-latest\n",
            "Usando Google Gemini: gemini-1.5-flash-latest\n",
            "Configurando a cadeia de QA (RetrievalQA) para recuperar k=4 chunks...\n",
            "Cadeia de QA configurada.\n",
            "\n",
            "--- Iniciando Sessão de Perguntas e Respostas ---\n",
            "\n",
            "[Pergunta 1/5]: 1. O que é saude coletiva?\n",
            "[Resposta]: The provided text does not define \"saúde coletiva\".  While the text discusses health promotion, the health system in Brazil, and the social determinants of health, it does not offer a definition of the term \"saúde coletiva\".\n",
            "(Tempo: 0.82s | Confiança Recuperação (Avg Score): 0.3814)\n",
            "  (Score médio de relevância dos 4 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 2/5]: 2. Quais as doenças mais comuns do Brasil?\n",
            "[Resposta]: I am sorry, but this document does not contain information on the most common diseases in Brazil.\n",
            "(Tempo: 0.47s | Confiança Recuperação (Avg Score): 0.2741)\n",
            "  (Score médio de relevância dos 4 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 3/5]: 3. Quais as metas propostas pela Organização Mundial da Saude?\n",
            "[Resposta]: This document does not contain information about the World Health Organization's proposed goals.\n",
            "(Tempo: 0.42s | Confiança Recuperação (Avg Score): 0.4462)\n",
            "  (Score médio de relevância dos 4 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 4/5]: 4. Que fatores influenciam as doenças que as pessoas contraem?\n",
            "[Resposta]: Based on the provided text, several factors influence the diseases people contract.  These include lifestyle choices (diet, exercise, alcohol consumption, smoking, drug use), stress, age, and social determinants of health such as  economic conditions, access to healthcare, and environmental factors.  The text also highlights the impact of industrialization and economic development on disease prevalence.\n",
            "(Tempo: 0.80s | Confiança Recuperação (Avg Score): 0.3797)\n",
            "  (Score médio de relevância dos 4 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 5/5]: 5. O que é o modelo da vigilância da saude?\n",
            "[Resposta]: Based on the provided text, I cannot answer your question.  The text discusses the relationship between health and social factors, the history of health promotion,  the importance of preventative care, and aspects of women's health, including sexual violence and sexually transmitted infections.  There is mention of the Brazilian public health system (SUS) and chronic non-communicable diseases, but no specific question is posed within the text to which I can provide an answer.\n",
            "(Tempo: 0.86s | Confiança Recuperação (Avg Score): 0.3101)\n",
            "  (Score médio de relevância dos 4 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "===== Concluída Configuração: MiniLM_LargeChunks_k4 =====\n",
            "\n",
            "===== Processando Configuração: QA-MiniLM_SmallChunks_k5 =====\n",
            "Dividindo documentos em chunks (tamanho: 800, sobreposição: 150)\n",
            "Número de chunks criados: 545\n",
            "Carregando embeddings HuggingFace: sentence-transformers/multi-qa-MiniLM-L6-cos-v1 no dispositivo: cpu\n",
            "Carregando Vector Store FAISS existente de: /content/drive/MyDrive/RAG/faiss_index_config_B\n",
            "Vector Store carregado com sucesso.\n",
            "Configurando LLM Provider: gemini com modelo: gemini-1.5-flash-latest\n",
            "Usando Google Gemini: gemini-1.5-flash-latest\n",
            "Configurando a cadeia de QA (RetrievalQA) para recuperar k=5 chunks...\n",
            "Cadeia de QA configurada.\n",
            "\n",
            "--- Iniciando Sessão de Perguntas e Respostas ---\n",
            "\n",
            "[Pergunta 1/5]: 1. O que é saude coletiva?\n",
            "[Resposta]: Based on the provided text, I cannot answer what \"saúde coletiva\" is.  The text mentions it frequently and discusses aspects of it, such as promotion of health,  attention to odontopathies, and the role of community health workers, but it does not define the term itself.\n",
            "(Tempo: 0.83s | Confiança Recuperação (Avg Score): 0.5536)\n",
            "  (Score médio de relevância dos 5 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 2/5]: 2. Quais as doenças mais comuns do Brasil?\n",
            "[Resposta]: I'm sorry, but this text does not list the most common diseases in Brazil.  While it mentions some diseases like Hansen's disease and discusses aspects of healthcare in Brazil, it does not provide a list of the most common illnesses.\n",
            "(Tempo: 0.66s | Confiança Recuperação (Avg Score): 0.3200)\n",
            "  (Score médio de relevância dos 5 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 3/5]: 3. Quais as metas propostas pela Organização Mundial da Saude?\n",
            "[Resposta]: This document does not contain information about the goals proposed by the World Health Organization.\n",
            "(Tempo: 0.43s | Confiança Recuperação (Avg Score): 0.4196)\n",
            "  (Score médio de relevância dos 5 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 4/5]: 4. Que fatores influenciam as doenças que as pessoas contraem?\n",
            "[Resposta]: Based on the provided text, several factors influence the diseases people contract.  These include:\n",
            "\n",
            "* **Age:**  Infancy and old age are mentioned as influencing factors.\n",
            "* **Sex:**  The text mentions sex as a factor.\n",
            "* **Location:**  Living in urban areas or near forests is cited as influential.\n",
            "* **Time of year:** Seasons and months are mentioned as factors.\n",
            "* **Occupation:**  Examples given include sex workers and construction workers.\n",
            "* **Diet:**  Poor diet, low in salt and fat, and carbohydrate restriction for diabetics are mentioned.\n",
            "* **Weight:** Maintaining a healthy weight is highlighted.\n",
            "* **Lifestyle:**  Sedentary lifestyles and lack of leisure activities are implicated.\n",
            "* **Stress:** Stress from industrialization and economic development is mentioned.\n",
            "* **Alcohol consumption:** Alcohol use is listed as a factor.\n",
            "* **Smoking:** Tobacco use is included.\n",
            "* **Drug addiction:** Drug addiction is explicitly named.\n",
            "\n",
            "\n",
            "The text also notes that before the 20th century, the focus was primarily on the interaction between the infectious agent and the host, neglecting other influencing factors.  The development of vaccines and a better understanding of infectious agents shifted this perspective.\n",
            "(Tempo: 1.89s | Confiança Recuperação (Avg Score): 0.4143)\n",
            "  (Score médio de relevância dos 5 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "\n",
            "[Pergunta 5/5]: 5. O que é o modelo da vigilância da saude?\n",
            "[Resposta]: Based on the provided text, the model of health surveillance is described as a recent and expanding field in Brazil.  It emerged from the decentralization promoted by the SUS (Sistema Único de Saúde) in the 1988 Constitution.  This model emphasizes decentralization, increased popular participation, and social control over health issues.\n",
            "(Tempo: 0.71s | Confiança Recuperação (Avg Score): 0.4100)\n",
            "  (Score médio de relevância dos 5 chunks recuperados. 1 = Mais Relevante, 0 = Menos Relevante)\n",
            "--------------------------------------------------\n",
            "===== Concluída Configuração: QA-MiniLM_SmallChunks_k5 =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Geração da Tabela Comparativa ---\n",
        "print(\"\\n\\n===== Tabela Comparativa de Resultados =====\")\n",
        "\n",
        "# Verificar se temos resultados para comparar\n",
        "if not all_results or len(all_results) < 2:\n",
        "     print(\"Não há resultados suficientes para comparação (necessário pelo menos 2 configurações bem-sucedidas).\")\n",
        "else:\n",
        "    # Estruturar dados para o DataFrame\n",
        "    comparison_data = []\n",
        "    num_questions = len(questions)\n",
        "\n",
        "    for i in range(num_questions):\n",
        "        row_data = {\"Pergunta\": questions[i]}\n",
        "        for config_name, results in all_results.items():\n",
        "            if i < len(results): # Verifica se há resultado para esta pergunta nesta config\n",
        "                res = results[i]\n",
        "                # Usar nomes de coluna mais curtos e claros para CSV\n",
        "                row_data[f\"{config_name}_Resp\"] = res.get('resposta', 'N/A')\n",
        "                row_data[f\"{config_name}_T(s)\"] = res.get('tempo_s', '-')\n",
        "                row_data[f\"{config_name}_Score\"] = res.get('avg_relevance_score', '-')\n",
        "            else: # Caso de erro ou menos perguntas processadas\n",
        "                row_data[f\"{config_name}_Resp\"] = \"N/A (Erro ou não processado)\"\n",
        "                row_data[f\"{config_name}_T(s)\"] = \"-\"\n",
        "                row_data[f\"{config_name}_Score\"] = \"-\"\n",
        "        comparison_data.append(row_data)\n",
        "\n",
        "    # Criar DataFrame\n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "\n",
        "    # Configurar Pandas para mostrar mais texto nas colunas (opcional)\n",
        "    pd.set_option('display.max_colwidth', 150) # Ajuste o valor conforme necessário\n",
        "    pd.set_option('display.width', 1000) # Ajuste para largura da tela\n",
        "\n",
        "    # Exibir DataFrame no Colab\n",
        "    print(\"\\n--- Visualização da Tabela ---\")\n",
        "    display(df_comparison)\n",
        "    # Se não estiver no Colab ou quiser output em texto puro:\n",
        "    # print(df_comparison.to_string())\n",
        "\n",
        "    # --- Salvar DataFrame em Arquivo CSV ---\n",
        "    output_filename = \"rag_comparison_results.csv\"\n",
        "    output_path = os.path.join(BASE_DRIVE_PATH, output_filename)\n",
        "\n",
        "    try:\n",
        "        # Salvar em CSV com encoding UTF-8 (bom para caracteres especiais)\n",
        "        # index=False para não salvar o índice numérico do pandas no arquivo\n",
        "        df_comparison.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "        print(f\"\\n--- Tabela de comparação salva com sucesso em: ---\")\n",
        "        print(output_path)\n",
        "        if not DRIVE_MOUNTED:\n",
        "             print(\"\\nAVISO: O arquivo foi salvo no armazenamento temporário do Colab.\")\n",
        "             print(\"Faça o download manualmente no painel 'Arquivos' antes de fechar a sessão!\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- ERRO ao salvar a tabela em arquivo: {e} ---\")\n",
        "        print(f\"Verifique as permissões de escrita em: {BASE_DRIVE_PATH}\")\n",
        "\n",
        "print(\"\\nProcesso de Comparação RAG concluído.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "mm6arTnxfOFH",
        "outputId": "e84a3220-2d09-4bde-9c2d-18c9800b31d9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "===== Tabela Comparativa de Resultados =====\n",
            "\n",
            "--- Visualização da Tabela ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                         Pergunta                                                                                                                             MiniLM_LargeChunks_k4_Resp MiniLM_LargeChunks_k4_T(s)  MiniLM_LargeChunks_k4_Score                                                                                                                          QA-MiniLM_SmallChunks_k5_Resp QA-MiniLM_SmallChunks_k5_T(s)  QA-MiniLM_SmallChunks_k5_Score\n",
              "0                                      1. O que é saude coletiva?  The provided text does not define \"saúde coletiva\".  While the text discusses health promotion, the health system in Brazil, and the social determ...                          -                     0.381385  Based on the provided text, I cannot answer what \"saúde coletiva\" is.  The text mentions it frequently and discusses aspects of it, such as promot...                             -                        0.553581\n",
              "1                      2. Quais as doenças mais comuns do Brasil?                                                      I am sorry, but this document does not contain information on the most common diseases in Brazil.                          -                     0.274078  I'm sorry, but this text does not list the most common diseases in Brazil.  While it mentions some diseases like Hansen's disease and discusses as...                             -                        0.320044\n",
              "2  3. Quais as metas propostas pela Organização Mundial da Saude?                                                       This document does not contain information about the World Health Organization's proposed goals.                          -                     0.446222                                                  This document does not contain information about the goals proposed by the World Health Organization.                             -                        0.419588\n",
              "3  4. Que fatores influenciam as doenças que as pessoas contraem?  Based on the provided text, several factors influence the diseases people contract.  These include lifestyle choices (diet, exercise, alcohol cons...                          -                     0.379653  Based on the provided text, several factors influence the diseases people contract.  These include:\\n\\n* **Age:**  Infancy and old age are mention...                             -                        0.414291\n",
              "4                     5. O que é o modelo da vigilância da saude?  Based on the provided text, I cannot answer your question.  The text discusses the relationship between health and social factors, the history of ...                          -                     0.310083  Based on the provided text, the model of health surveillance is described as a recent and expanding field in Brazil.  It emerged from the decentra...                             -                        0.409978"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd4f500c-0165-48b1-a678-5baef6262aea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pergunta</th>\n",
              "      <th>MiniLM_LargeChunks_k4_Resp</th>\n",
              "      <th>MiniLM_LargeChunks_k4_T(s)</th>\n",
              "      <th>MiniLM_LargeChunks_k4_Score</th>\n",
              "      <th>QA-MiniLM_SmallChunks_k5_Resp</th>\n",
              "      <th>QA-MiniLM_SmallChunks_k5_T(s)</th>\n",
              "      <th>QA-MiniLM_SmallChunks_k5_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. O que é saude coletiva?</td>\n",
              "      <td>The provided text does not define \"saúde coletiva\".  While the text discusses health promotion, the health system in Brazil, and the social determ...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.381385</td>\n",
              "      <td>Based on the provided text, I cannot answer what \"saúde coletiva\" is.  The text mentions it frequently and discusses aspects of it, such as promot...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.553581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2. Quais as doenças mais comuns do Brasil?</td>\n",
              "      <td>I am sorry, but this document does not contain information on the most common diseases in Brazil.</td>\n",
              "      <td>-</td>\n",
              "      <td>0.274078</td>\n",
              "      <td>I'm sorry, but this text does not list the most common diseases in Brazil.  While it mentions some diseases like Hansen's disease and discusses as...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.320044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3. Quais as metas propostas pela Organização Mundial da Saude?</td>\n",
              "      <td>This document does not contain information about the World Health Organization's proposed goals.</td>\n",
              "      <td>-</td>\n",
              "      <td>0.446222</td>\n",
              "      <td>This document does not contain information about the goals proposed by the World Health Organization.</td>\n",
              "      <td>-</td>\n",
              "      <td>0.419588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4. Que fatores influenciam as doenças que as pessoas contraem?</td>\n",
              "      <td>Based on the provided text, several factors influence the diseases people contract.  These include lifestyle choices (diet, exercise, alcohol cons...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.379653</td>\n",
              "      <td>Based on the provided text, several factors influence the diseases people contract.  These include:\\n\\n* **Age:**  Infancy and old age are mention...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.414291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5. O que é o modelo da vigilância da saude?</td>\n",
              "      <td>Based on the provided text, I cannot answer your question.  The text discusses the relationship between health and social factors, the history of ...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.310083</td>\n",
              "      <td>Based on the provided text, the model of health surveillance is described as a recent and expanding field in Brazil.  It emerged from the decentra...</td>\n",
              "      <td>-</td>\n",
              "      <td>0.409978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd4f500c-0165-48b1-a678-5baef6262aea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd4f500c-0165-48b1-a678-5baef6262aea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd4f500c-0165-48b1-a678-5baef6262aea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9db62ca1-0548-4411-9565-fa123f985df5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9db62ca1-0548-4411-9565-fa123f985df5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9db62ca1-0548-4411-9565-fa123f985df5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1cd4ed16-7de6-4e72-aafb-96b07730e13d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_comparison')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1cd4ed16-7de6-4e72-aafb-96b07730e13d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_comparison');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_comparison",
              "summary": "{\n  \"name\": \"df_comparison\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Pergunta\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2. Quais as doen\\u00e7as mais comuns do Brasil?\",\n          \"5. O que \\u00e9 o modelo da vigil\\u00e2ncia da saude?\",\n          \"3. Quais as metas propostas pela Organiza\\u00e7\\u00e3o Mundial da Saude?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MiniLM_LargeChunks_k4_Resp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I am sorry, but this document does not contain information on the most common diseases in Brazil.\",\n          \"Based on the provided text, I cannot answer your question.  The text discusses the relationship between health and social factors, the history of health promotion,  the importance of preventative care, and aspects of women's health, including sexual violence and sexually transmitted infections.  There is mention of the Brazilian public health system (SUS) and chronic non-communicable diseases, but no specific question is posed within the text to which I can provide an answer.\",\n          \"This document does not contain information about the World Health Organization's proposed goals.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MiniLM_LargeChunks_k4_T(s)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MiniLM_LargeChunks_k4_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2740775942802429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"QA-MiniLM_SmallChunks_k5_Resp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I'm sorry, but this text does not list the most common diseases in Brazil.  While it mentions some diseases like Hansen's disease and discusses aspects of healthcare in Brazil, it does not provide a list of the most common illnesses.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"QA-MiniLM_SmallChunks_k5_T(s)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"-\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"QA-MiniLM_SmallChunks_k5_Score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3200439512729645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tabela de comparação salva com sucesso em: ---\n",
            "/content/drive/MyDrive/RAG/rag_comparison_results.csv\n",
            "\n",
            "Processo de Comparação RAG concluído.\n"
          ]
        }
      ]
    }
  ]
}