{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwPD7nY0Vf671pTMZQ+gaO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieltalon/trabalho_RAG/blob/main/3_verifica_respostas_taxa_acerto_IA_NAIVE_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qPbOlpfsxpKk",
        "outputId": "a3ebbc4b-8881-4998-b969-fc5be3c9dc47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado com sucesso!\n",
            "Diretório de índices '/content/drive/MyDrive/Indexes/' verificado/criado.\n",
            "Diretório de resultados '/content/drive/MyDrive/Resultados/' verificado/criado.\n",
            "API Key do Google configurada com sucesso via Colab Secrets.\n",
            "--- Iniciando Setup RAG (com Persistência) ---\n",
            "Carregando índice FAISS de /content/drive/MyDrive/Indexes/medicina_knowledge.index...\n",
            "Carregando chunks de texto de /content/drive/MyDrive/Indexes/medicina_knowledge_chunks.pkl...\n",
            "Índice (359 vetores) e Chunks (359) carregados com sucesso.\n",
            "--- Setup RAG Concluído (a partir de arquivos salvos) ---\n",
            "\n",
            "--- Iniciando Script de Avaliação com RAG (Múltiplos PDFs e Persistência) ---\n",
            "\n",
            "Carregando dados do JSON...\n",
            "Total de questões no arquivo: 670\n",
            "Filtrando por áreas: Ginecologia, Obstetrícia, Pediatria...\n",
            "Número de questões filtradas: 209\n",
            "Limitando o processamento às primeiras 150 questões filtradas.\n",
            "Iniciando avaliação RAG de 150 questões em lotes de 15...\n",
            "\n",
            "--- Processando Lote RAG 1/10 (Questões 1 a 15) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 1 (ID: 2021_1)...\n",
            "    Recuperando para questão 2 (ID: 2021_2)...\n",
            "    Recuperando para questão 3 (ID: 2021_4)...\n",
            "    Recuperando para questão 4 (ID: 2021_6)...\n",
            "    Recuperando para questão 5 (ID: 2021_15)...\n",
            "    Recuperando para questão 6 (ID: 2021_19)...\n",
            "    Recuperando para questão 7 (ID: 2021_20)...\n",
            "    Recuperando para questão 8 (ID: 2021_25)...\n",
            "    Recuperando para questão 9 (ID: 2021_33)...\n",
            "    Recuperando para questão 10 (ID: 2021_34)...\n",
            "    Recuperando para questão 11 (ID: 2021_36)...\n",
            "    Recuperando para questão 12 (ID: 2021_37)...\n",
            "    Recuperando para questão 13 (ID: 2021_38)...\n",
            "    Recuperando para questão 14 (ID: 2021_43)...\n",
            "    Recuperando para questão 15 (ID: 2021_45)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 2/10 (Questões 16 a 30) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 16 (ID: 2021_50)...\n",
            "    Recuperando para questão 17 (ID: 2021_54)...\n",
            "    Recuperando para questão 18 (ID: 2021_55)...\n",
            "    Recuperando para questão 19 (ID: 2021_58)...\n",
            "    Recuperando para questão 20 (ID: 2021_61)...\n",
            "    Recuperando para questão 21 (ID: 2021_64)...\n",
            "    Recuperando para questão 22 (ID: 2021_68)...\n",
            "    Recuperando para questão 23 (ID: 2021_69)...\n",
            "    Recuperando para questão 24 (ID: 2021_70)...\n",
            "    Recuperando para questão 25 (ID: 2021_71)...\n",
            "    Recuperando para questão 26 (ID: 2021_72)...\n",
            "    Recuperando para questão 27 (ID: 2021_77)...\n",
            "    Recuperando para questão 28 (ID: 2021_78)...\n",
            "    Recuperando para questão 29 (ID: 2021_81)...\n",
            "    Recuperando para questão 30 (ID: 2021_85)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 3/10 (Questões 31 a 45) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 31 (ID: 2021_87)...\n",
            "    Recuperando para questão 32 (ID: 2021_89)...\n",
            "    Recuperando para questão 33 (ID: 2021_90)...\n",
            "    Recuperando para questão 34 (ID: 2021_95)...\n",
            "    Recuperando para questão 35 (ID: 2021_97)...\n",
            "    Recuperando para questão 36 (ID: 2022_3)...\n",
            "    Recuperando para questão 37 (ID: 2022_4)...\n",
            "    Recuperando para questão 38 (ID: 2022_8)...\n",
            "    Recuperando para questão 39 (ID: 2022_9)...\n",
            "    Recuperando para questão 40 (ID: 2022_13)...\n",
            "    Recuperando para questão 41 (ID: 2022_14)...\n",
            "    Recuperando para questão 42 (ID: 2022_18)...\n",
            "    Recuperando para questão 43 (ID: 2022_19)...\n",
            "    Recuperando para questão 44 (ID: 2022_24)...\n",
            "    Recuperando para questão 45 (ID: 2022_25)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 4/10 (Questões 46 a 60) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 46 (ID: 2022_28)...\n",
            "    Recuperando para questão 47 (ID: 2022_29)...\n",
            "    Recuperando para questão 48 (ID: 2022_33)...\n",
            "    Recuperando para questão 49 (ID: 2022_34)...\n",
            "    Recuperando para questão 50 (ID: 2022_38)...\n",
            "    Recuperando para questão 51 (ID: 2022_39)...\n",
            "    Recuperando para questão 52 (ID: 2022_43)...\n",
            "    Recuperando para questão 53 (ID: 2022_44)...\n",
            "    Recuperando para questão 54 (ID: 2022_48)...\n",
            "    Recuperando para questão 55 (ID: 2022_49)...\n",
            "    Recuperando para questão 56 (ID: 2022_53)...\n",
            "    Recuperando para questão 57 (ID: 2022_54)...\n",
            "    Recuperando para questão 58 (ID: 2022_58)...\n",
            "    Recuperando para questão 59 (ID: 2022_59)...\n",
            "    Recuperando para questão 60 (ID: 2022_63)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 5/10 (Questões 61 a 75) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 61 (ID: 2022_64)...\n",
            "    Recuperando para questão 62 (ID: 2022_65)...\n",
            "    Recuperando para questão 63 (ID: 2022_68)...\n",
            "    Recuperando para questão 64 (ID: 2022_74)...\n",
            "    Recuperando para questão 65 (ID: 2022_79)...\n",
            "    Recuperando para questão 66 (ID: 2022_83)...\n",
            "    Recuperando para questão 67 (ID: 2022_88)...\n",
            "    Recuperando para questão 68 (ID: 2022_89)...\n",
            "    Recuperando para questão 69 (ID: 2022_90)...\n",
            "    Recuperando para questão 70 (ID: 2022_93)...\n",
            "    Recuperando para questão 71 (ID: 2022_94)...\n",
            "    Recuperando para questão 72 (ID: 2022_98)...\n",
            "    Recuperando para questão 73 (ID: 2022_99)...\n",
            "    Recuperando para questão 74 (ID: 2022_100)...\n",
            "    Recuperando para questão 75 (ID: 2023_3)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 6/10 (Questões 76 a 90) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 76 (ID: 2023_4)...\n",
            "    Recuperando para questão 77 (ID: 2023_8)...\n",
            "    Recuperando para questão 78 (ID: 2023_9)...\n",
            "    Recuperando para questão 79 (ID: 2023_10)...\n",
            "    Recuperando para questão 80 (ID: 2023_14)...\n",
            "    Recuperando para questão 81 (ID: 2023_18)...\n",
            "    Recuperando para questão 82 (ID: 2023_19)...\n",
            "    Recuperando para questão 83 (ID: 2023_23)...\n",
            "    Recuperando para questão 84 (ID: 2023_24)...\n",
            "    Recuperando para questão 85 (ID: 2023_25)...\n",
            "    Recuperando para questão 86 (ID: 2023_28)...\n",
            "    Recuperando para questão 87 (ID: 2023_29)...\n",
            "    Recuperando para questão 88 (ID: 2023_33)...\n",
            "    Recuperando para questão 89 (ID: 2023_34)...\n",
            "    Recuperando para questão 90 (ID: 2023_39)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 7/10 (Questões 91 a 105) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 91 (ID: 2023_40)...\n",
            "    Recuperando para questão 92 (ID: 2023_43)...\n",
            "    Recuperando para questão 93 (ID: 2023_44)...\n",
            "    Recuperando para questão 94 (ID: 2023_45)...\n",
            "    Recuperando para questão 95 (ID: 2023_51)...\n",
            "    Recuperando para questão 96 (ID: 2023_53)...\n",
            "    Recuperando para questão 97 (ID: 2023_54)...\n",
            "    Recuperando para questão 98 (ID: 2023_59)...\n",
            "    Recuperando para questão 99 (ID: 2023_63)...\n",
            "    Recuperando para questão 100 (ID: 2023_64)...\n",
            "    Recuperando para questão 101 (ID: 2023_68)...\n",
            "    Recuperando para questão 102 (ID: 2023_69)...\n",
            "    Recuperando para questão 103 (ID: 2023_73)...\n",
            "    Recuperando para questão 104 (ID: 2023_74)...\n",
            "    Recuperando para questão 105 (ID: 2023_78)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 8/10 (Questões 106 a 120) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 106 (ID: 2023_79)...\n",
            "    Recuperando para questão 107 (ID: 2023_80)...\n",
            "    Recuperando para questão 108 (ID: 2023_84)...\n",
            "    Recuperando para questão 109 (ID: 2023_88)...\n",
            "    Recuperando para questão 110 (ID: 2023_89)...\n",
            "    Recuperando para questão 111 (ID: 2023_93)...\n",
            "    Recuperando para questão 112 (ID: 2023_94)...\n",
            "    Recuperando para questão 113 (ID: 2023_98)...\n",
            "    Recuperando para questão 114 (ID: 2023_99)...\n",
            "    Recuperando para questão 115 (ID: 2023_13)...\n",
            "    Recuperando para questão 116 (ID: 2023_15)...\n",
            "    Recuperando para questão 117 (ID: 2023_35)...\n",
            "    Recuperando para questão 118 (ID: 2023_38)...\n",
            "    Recuperando para questão 119 (ID: 2023_42)...\n",
            "    Recuperando para questão 120 (ID: 2023_49)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 9/10 (Questões 121 a 135) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 121 (ID: 2023_70)...\n",
            "    Recuperando para questão 122 (ID: 2023_83)...\n",
            "    Recuperando para questão 123 (ID: 2023_100)...\n",
            "    Recuperando para questão 124 (ID: 2024_1)...\n",
            "    Recuperando para questão 125 (ID: 2024_3)...\n",
            "    Recuperando para questão 126 (ID: 2024_4)...\n",
            "    Recuperando para questão 127 (ID: 2024_8)...\n",
            "    Recuperando para questão 128 (ID: 2024_9)...\n",
            "    Recuperando para questão 129 (ID: 2024_13)...\n",
            "    Recuperando para questão 130 (ID: 2024_14)...\n",
            "    Recuperando para questão 131 (ID: 2024_18)...\n",
            "    Recuperando para questão 132 (ID: 2024_19)...\n",
            "    Recuperando para questão 133 (ID: 2024_20)...\n",
            "    Recuperando para questão 134 (ID: 2024_23)...\n",
            "    Recuperando para questão 135 (ID: 2024_24)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "--- Fim do Lote RAG. Aguardando 3 segundos... ---\n",
            "\n",
            "--- Processando Lote RAG 10/10 (Questões 136 a 150) ---\n",
            "  Recuperando contexto RAG para o lote...\n",
            "    Recuperando para questão 136 (ID: 2024_25)...\n",
            "    Recuperando para questão 137 (ID: 2024_28)...\n",
            "    Recuperando para questão 138 (ID: 2024_29)...\n",
            "    Recuperando para questão 139 (ID: 2024_30)...\n",
            "    Recuperando para questão 140 (ID: 2024_33)...\n",
            "    Recuperando para questão 141 (ID: 2024_34)...\n",
            "    Recuperando para questão 142 (ID: 2024_38)...\n",
            "    Recuperando para questão 143 (ID: 2024_39)...\n",
            "    Recuperando para questão 144 (ID: 2024_40)...\n",
            "    Recuperando para questão 145 (ID: 2024_44)...\n",
            "    Recuperando para questão 146 (ID: 2024_48)...\n",
            "    Recuperando para questão 147 (ID: 2024_49)...\n",
            "    Recuperando para questão 148 (ID: 2024_53)...\n",
            "    Recuperando para questão 149 (ID: 2024_54)...\n",
            "    Recuperando para questão 150 (ID: 2024_58)...\n",
            "  Formatando prompt aumentado para a IA...\n",
            "  Enviando lote aumentado para a IA...\n",
            "  Processando respostas do lote...\n",
            "\n",
            "Avaliação RAG de todos os lotes concluída.\n",
            "Resultados salvos com sucesso em '/content/drive/MyDrive/Resultados/resultados_avaliacao_ia_naive_rag_lote_2025-05-03-12-15.csv' no Google Drive.\n",
            "Log de resumo salvo com sucesso em '/content/drive/MyDrive/Resultados/log_avaliacao_ia_naive_rag_lote_2025-05-03-12-15.txt'\n",
            "\n",
            "--- Resumo da Avaliação (com RAG de Múltiplos PDFs) ---\n",
            "Modelo IA Utilizado: gemini-1.5-flash\n",
            "Temperatura Utilizada: 0.1\n",
            "Fonte de Conhecimento RAG: Índice e chunks carregados de /content/drive/MyDrive/Indexes/\n",
            "Total de Questões Processadas: 150\n",
            "Total de Acertos: 114\n",
            "Total de Erros da IA: 0\n",
            "  - Erros de Parsing/Ausente: 0\n",
            "  - Erros de API/Outros: 0\n",
            "  - Respostas Bloqueadas: 0\n",
            "Questões Válidas para Acurácia: 150\n",
            "\n",
            "Acurácia Geral (sobre todas): 76.00%\n",
            "Acurácia (excluindo erros IA): 76.00%\n",
            "\n",
            "Acurácia por Área Médica (sobre válidas):\n",
            "  - Ginecologia: 72.86% (51 de 70 válidas / 70 total / 0 erros IA)\n",
            "  - Obstetrícia: 72.09% (31 de 43 válidas / 43 total / 0 erros IA)\n",
            "  - Pediatria: 79.45% (58 de 73 válidas / 73 total / 0 erros IA)\n",
            "\n",
            "Resultados detalhados salvos em: /content/drive/MyDrive/Resultados/resultados_avaliacao_ia_naive_rag_lote_2025-05-03-12-15.csv\n",
            "Log de resumo salvo em: /content/drive/MyDrive/Resultados/log_avaliacao_ia_naive_rag_lote_2025-05-03-12-15.txt\n",
            "\n",
            "--- Fim do Script ---\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Avaliação de IA em Questões Médicas (Adaptado para Google Colab - COM RAG de Múltiplos PDFs, Persistência de Índice, BATCH API e Log Timestamped)\n",
        "\n",
        "Este script avalia o desempenho de um modelo de IA generativa (Google Gemini)\n",
        "em responder questões de múltipla escolha de provas de medicina,\n",
        "filtradas por áreas específicas. Utiliza RAG com múltiplos PDFs de um diretório,\n",
        "salva/carrega o índice vetorial FAISS e os chunks de texto para persistência,\n",
        "envia perguntas em lotes para a API de geração e salva resultados e logs com timestamp.\n",
        "\"\"\"\n",
        "\n",
        "# @title 1. Instalar Bibliotecas e Importar Módulos Necessários\n",
        "# Instala as bibliotecas necessárias no ambiente Colab\n",
        "!pip install -q google-generativeai pandas pypdf2 faiss-cpu numpy\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive, files # Módulos específicos do Colab\n",
        "from collections import defaultdict\n",
        "import io\n",
        "from PyPDF2 import PdfReader # Para ler o PDF\n",
        "import faiss # Para o banco de dados vetorial\n",
        "import os # Para listar arquivos e verificar existência\n",
        "import pickle # Para salvar/carregar a lista de chunks\n",
        "from datetime import datetime # Para timestamp\n",
        "\n",
        "# @title 2. Definir Constantes e Configurações\n",
        "\n",
        "# --- Constantes de Configuração ---\n",
        "# Caminhos atualizados conforme sua especificação\n",
        "JSON_FILE_PATH = '/content/drive/MyDrive/Questoes/questoes_2021_2022_2023_2024_limit700_classificadas_lote.json' #@param {type:\"string\"}\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Resultados/' #@param {type:\"string\"} # Diretório para salvar CSV e Log\n",
        "BASE_CSV_FILENAME = 'resultados_avaliacao_ia_naive_rag_lote' #@param {type:\"string\"}\n",
        "BASE_LOG_FILENAME = 'log_avaliacao_ia_naive_rag_lote' #@param {type:\"string\"}\n",
        "AREAS_TO_FILTER = [\"Ginecologia\", \"Obstetrícia\", \"Pediatria\"] #@param\n",
        "\n",
        "# --- Constantes RAG ---\n",
        "KNOWLEDGE_BASE_DIR = '/content/drive/MyDrive/Knowledge_Base/' #@param {type:\"string\"} # Diretório com os PDFs\n",
        "INDEXES_DIR = '/content/drive/MyDrive/Indexes/' #@param {type:\"string\"} # Diretório para salvar/carregar índices\n",
        "FAISS_INDEX_PATH = os.path.join(INDEXES_DIR, 'medicina_knowledge.index') # Nome do arquivo do índice\n",
        "TEXT_CHUNKS_PATH = os.path.join(INDEXES_DIR, 'medicina_knowledge_chunks.pkl') # Nome do arquivo dos chunks\n",
        "\n",
        "CHUNK_SIZE = 1000 #@param {type:\"integer\"}\n",
        "CHUNK_OVERLAP = 100 #@param {type:\"integer\"}\n",
        "TOP_K_RAG = 3 #@param {type:\"integer\"}\n",
        "EMBEDDING_MODEL = 'models/text-embedding-004' #@param {type:\"string\"}\n",
        "\n",
        "# --- Parâmetros de Processamento ---\n",
        "BATCH_SIZE = 15 #@param {type:\"integer\"}\n",
        "DELAY_BETWEEN_BATCHES = 3 #@param {type:\"integer\"}\n",
        "MAX_RETRIES = 3 #@param {type:\"integer\"}\n",
        "MAX_QUESTIONS_TO_PROCESS = 150 #@param {type:\"integer\"}\n",
        "GEMINI_MODEL_NAME = 'gemini-1.5-flash' #@param {type:\"string\"}\n",
        "COLAB_SECRET_KEY_NAME = 'GOOGLE_API_KEY' #@param {type:\"string\"}\n",
        "AI_TEMPERATURE = 0.1 #@param {type:\"number\"}\n",
        "\n",
        "#-------------------------------------\n",
        "\n",
        "# @title 3. Montar Google Drive e Criar Diretórios\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive montado com sucesso!\")\n",
        "    # Cria os diretórios de índices e resultados se não existirem\n",
        "    os.makedirs(INDEXES_DIR, exist_ok=True)\n",
        "    os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "    print(f\"Diretório de índices '{INDEXES_DIR}' verificado/criado.\")\n",
        "    print(f\"Diretório de resultados '{RESULTS_DIR}' verificado/criado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao montar Google Drive ou criar diretórios: {e}\")\n",
        "    # exit()\n",
        "\n",
        "# @title 4. Configurar API Key do Google\n",
        "try:\n",
        "    API_KEY = userdata.get(COLAB_SECRET_KEY_NAME)\n",
        "    if not API_KEY:\n",
        "        raise ValueError(f\"Chave secreta '{COLAB_SECRET_KEY_NAME}' não encontrada ou vazia.\")\n",
        "    genai.configure(api_key=API_KEY)\n",
        "    print(\"API Key do Google configurada com sucesso via Colab Secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar a API Key: {e}\")\n",
        "    # exit()\n",
        "\n",
        "# @title 5. Funções Auxiliares (Carregar, Filtrar, RAG, Formatar, Chamar IA, Parsear, Avaliar, Salvar)\n",
        "\n",
        "# --- Funções de Carregamento e Filtragem (sem alterações) ---\n",
        "def load_json_data(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo JSON não encontrado em '{filepath}'.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Erro: Falha ao decodificar o arquivo JSON '{filepath}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Erro inesperado ao carregar o JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def filter_questions(data, areas):\n",
        "    filtered = []\n",
        "    if not data: return filtered\n",
        "    seen_ids = set()\n",
        "    for i, question in enumerate(data):\n",
        "        prova = question.get('prova', 'unk_prova'); numero = question.get('numero', f'idx_{i}')\n",
        "        question_id = f\"{prova}_{numero}\"\n",
        "        if question_id in seen_ids: continue\n",
        "        question_areas = question.get('areas_medicas', [])\n",
        "        if any(area in question_areas for area in areas):\n",
        "            if 'enunciado' in question and 'alternativas' in question and 'resposta' in question:\n",
        "                if isinstance(question['alternativas'], dict):\n",
        "                    filtered.append({\n",
        "                        'id': question_id, 'enunciado': question['enunciado'],\n",
        "                        'alternativas': question['alternativas'],\n",
        "                        'resposta_correta': str(question['resposta']).strip().upper(),\n",
        "                        'areas_medicas': question_areas,\n",
        "                        'continha_imagem': question.get('contains_img', False)\n",
        "                    })\n",
        "                    seen_ids.add(question_id)\n",
        "                else: print(f\"Aviso: Alternativas inválidas ID {question_id}. Pulando.\")\n",
        "            else: print(f\"Aviso: Questão ID {question_id} faltando campos. Pulando.\")\n",
        "    return filtered\n",
        "\n",
        "# --- Funções RAG (Modificada para carregar múltiplos PDFs e persistência) ---\n",
        "\n",
        "def load_and_split_pdfs_from_directory(directory_path, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
        "    \"\"\"Carrega TODOS os PDFs de um diretório, extrai texto e divide em chunks.\"\"\"\n",
        "    print(f\"Carregando e processando PDFs do diretório: {directory_path}\")\n",
        "    all_text_chunks = []\n",
        "    pdf_files_processed = [] # Lista para guardar nomes dos arquivos processados\n",
        "\n",
        "    try:\n",
        "        items_in_dir = os.listdir(directory_path)\n",
        "        pdf_files_found = [os.path.join(directory_path, item) for item in items_in_dir\n",
        "                           if os.path.isfile(os.path.join(directory_path, item)) and item.lower().endswith('.pdf')]\n",
        "\n",
        "        if not pdf_files_found:\n",
        "            print(f\"Nenhum arquivo PDF encontrado diretamente em '{directory_path}'.\")\n",
        "            return None, [] # Retorna None para chunks e lista vazia de arquivos\n",
        "\n",
        "        print(f\"Arquivos PDF encontrados: {len(pdf_files_found)}\")\n",
        "\n",
        "        for pdf_path in pdf_files_found:\n",
        "            pdf_filename = os.path.basename(pdf_path)\n",
        "            print(f\"  Processando: {pdf_filename}...\")\n",
        "            try:\n",
        "                reader = PdfReader(pdf_path)\n",
        "                pdf_full_text = \"\"\n",
        "                for page_num, page in enumerate(reader.pages):\n",
        "                    try: pdf_full_text += page.extract_text() + \"\\n\"\n",
        "                    except Exception as page_error: print(f\"    Aviso: Erro ao extrair página {page_num + 1} de {pdf_filename}: {page_error}\"); pdf_full_text += \"\\n[Erro na Página]\\n\"\n",
        "                start_index = 0; pdf_chunks_count = 0\n",
        "                while start_index < len(pdf_full_text):\n",
        "                    end_index = min(start_index + chunk_size, len(pdf_full_text))\n",
        "                    chunk_text = pdf_full_text[start_index:end_index]\n",
        "                    if chunk_text.strip(): all_text_chunks.append(chunk_text); pdf_chunks_count += 1\n",
        "                    next_start = start_index + chunk_size - chunk_overlap\n",
        "                    if next_start <= start_index: next_start = start_index + 1\n",
        "                    start_index = next_start\n",
        "                    if end_index == len(pdf_full_text): break\n",
        "                print(f\"    -> {pdf_chunks_count} chunks gerados.\")\n",
        "                pdf_files_processed.append(pdf_filename) # Adiciona à lista de processados\n",
        "\n",
        "            except Exception as file_error: print(f\"  Erro ao processar PDF '{pdf_filename}': {file_error}. Pulando.\"); continue\n",
        "\n",
        "        print(f\"Total de chunks de todos os PDFs processados: {len(all_text_chunks)}\")\n",
        "        return all_text_chunks, pdf_files_processed # Retorna chunks e nomes dos arquivos\n",
        "\n",
        "    except FileNotFoundError: print(f\"Erro: Diretório '{directory_path}' não encontrado.\"); return None, []\n",
        "    except Exception as e: print(f\"Erro inesperado ao listar/processar PDFs: {e}\"); return None, []\n",
        "\n",
        "\n",
        "def generate_embeddings(text_chunks, model_name=EMBEDDING_MODEL):\n",
        "    # (Função sem alterações)\n",
        "    if not text_chunks: return None\n",
        "    print(f\"Gerando embeddings para {len(text_chunks)} chunks usando {model_name}...\")\n",
        "    embeddings = []\n",
        "    count = 0\n",
        "    total = len(text_chunks)\n",
        "    embedding_batch_size = 100\n",
        "    for i in range(0, total, embedding_batch_size):\n",
        "        batch_chunks = text_chunks[i:min(i + embedding_batch_size, total)]\n",
        "        try:\n",
        "            result = genai.embed_content(model=model_name, content=batch_chunks, task_type=\"retrieval_document\")\n",
        "            embeddings.extend(result['embedding'])\n",
        "            count += len(batch_chunks)\n",
        "            print(f\"  Embeddings gerados para {count}/{total} chunks...\")\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao gerar embeddings para o lote {i//embedding_batch_size + 1}: {e}. Tentando individualmente...\")\n",
        "            for single_chunk in batch_chunks:\n",
        "                 try:\n",
        "                     result = genai.embed_content(model=model_name, content=single_chunk, task_type=\"retrieval_document\")\n",
        "                     embeddings.append(result['embedding'])\n",
        "                     count += 1\n",
        "                     if count % 50 == 0: print(f\"  Embeddings gerados para {count}/{total} chunks (modo individual)...\")\n",
        "                     time.sleep(0.2)\n",
        "                 except Exception as e_ind:\n",
        "                     print(f\"Erro ao gerar embedding para chunk individual: {e_ind}. Adicionando vetor nulo.\")\n",
        "                     embeddings.append([0.0] * 768)\n",
        "                     time.sleep(1)\n",
        "            count = min(i + embedding_batch_size, total)\n",
        "    if len(embeddings) != total: print(f\"Aviso: Número de embeddings ({len(embeddings)}) diferente do número de chunks ({total}).\")\n",
        "    print(\"Geração de embeddings concluída.\")\n",
        "    return np.array(embeddings).astype('float32')\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    # (Função sem alterações)\n",
        "    if embeddings is None or len(embeddings) == 0: print(\"Erro: Nenhum embedding para criar o índice.\"); return None\n",
        "    try:\n",
        "        dimension = embeddings.shape[1]\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "        index.add(embeddings)\n",
        "        print(f\"Índice FAISS criado com {index.ntotal} vetores de dimensão {dimension}.\")\n",
        "        return index\n",
        "    except Exception as e: print(f\"Erro ao criar índice FAISS: {e}\"); return None\n",
        "\n",
        "def retrieve_relevant_context(query, index, text_chunks, embedding_model=EMBEDDING_MODEL, top_k=TOP_K_RAG):\n",
        "    # (Função sem alterações)\n",
        "    if index is None or not text_chunks: return \"Erro: Índice ou chunks não disponíveis.\"\n",
        "    try:\n",
        "        query_embedding_result = genai.embed_content(model=embedding_model, content=query, task_type=\"retrieval_query\")\n",
        "        query_embedding = np.array([query_embedding_result['embedding']]).astype('float32')\n",
        "        distances, indices = index.search(query_embedding, top_k)\n",
        "        relevant_chunks = [text_chunks[idx] for idx in indices[0] if 0 <= idx < len(text_chunks)]\n",
        "        return \"\\n---\\n\".join(relevant_chunks)\n",
        "    except Exception as e: print(f\"Erro durante a recuperação RAG para query '{query[:50]}...': {e}\"); return \"Erro na recuperação de contexto.\"\n",
        "\n",
        "# --- Funções de Formatação, Chamada e Parsing da IA (sem alterações da versão RAG anterior) ---\n",
        "def format_augmented_batch_for_ai(batch_questions_with_context):\n",
        "    prompt = f\"Responda às seguintes questões de múltipla escolha usando o contexto fornecido para cada uma. Se o contexto não for suficiente, use seu conhecimento geral. Para cada questão, forneça APENAS a letra da alternativa correta, precedida pelo número da questão no lote e um ponto (ex: 1. A, 2. C, 3. B).\\n\\n\"\n",
        "    for i, data in enumerate(batch_questions_with_context):\n",
        "        question_data = data['question']; context = data['context']\n",
        "        prompt += f\"--- Questão {i+1} ---\\nContexto Recuperado:\\n{context}\\n---\\n\"\n",
        "        prompt += f\"Enunciado: {question_data['enunciado']}\\n\\nAlternativas:\\n\"\n",
        "        alternatives = question_data['alternativas']\n",
        "        try: sorted_keys = sorted(alternatives.keys())\n",
        "        except TypeError: sorted_keys = alternatives.keys()\n",
        "        for key in sorted_keys: prompt += f\"{key}: {alternatives[key]}\\n\"\n",
        "        if question_data['continha_imagem']: prompt += \"(Obs: Imagem não exibida)\\n\"\n",
        "        prompt += \"\\n\"\n",
        "    prompt += \"Respostas (formato: 1. Letra, 2. Letra, ...):\\n\"\n",
        "    return prompt\n",
        "\n",
        "def parse_ai_batch_response(response_text, batch_size):\n",
        "    answers = {}\n",
        "    if not response_text:\n",
        "        print(\"Aviso: Resposta da IA para o lote está vazia.\")\n",
        "        for i in range(batch_size): answers[i] = \"Erro: Resposta Vazia no Lote\"\n",
        "        return [answers.get(i, \"Erro: Resposta Ausente no Lote\") for i in range(batch_size)]\n",
        "    cleaned_text = re.sub(r'[*`]', '', response_text).strip()\n",
        "    pattern = re.compile(r\"^\\s*(\\d+)\\s*\\.\\s*([A-E])\\b\", re.MULTILINE)\n",
        "    found_answers = pattern.findall(cleaned_text.upper())\n",
        "    if found_answers:\n",
        "        for num_str, letter in found_answers:\n",
        "            try:\n",
        "                question_index = int(num_str) - 1\n",
        "                if 0 <= question_index < batch_size:\n",
        "                    if question_index not in answers: answers[question_index] = letter\n",
        "            except ValueError: print(f\"Aviso: Não foi possível converter número '{num_str}'.\")\n",
        "    else:\n",
        "        lines = cleaned_text.split('\\n')\n",
        "        potential_answers = [line.strip() for line in lines if len(line.strip()) == 1 and 'A' <= line.strip().upper() <= 'E']\n",
        "        if len(potential_answers) == batch_size:\n",
        "             print(\"Aviso: Usando formato alternativo de parsing (uma letra por linha).\")\n",
        "             for i, ans in enumerate(potential_answers): answers[i] = ans.upper()\n",
        "        else: print(f\"Aviso: Não foi possível parsear resposta do lote. Resposta:\\n{cleaned_text}\")\n",
        "    answer_list = [answers.get(i, \"Erro de Parsing no Lote\") for i in range(batch_size)]\n",
        "    return answer_list\n",
        "\n",
        "def get_ai_answers_for_augmented_batch(augmented_prompt, batch_size, model_name=GEMINI_MODEL_NAME, temperature=AI_TEMPERATURE, max_retries=MAX_RETRIES):\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    attempts = 0\n",
        "    generation_config = genai.types.GenerationConfig(temperature=temperature)\n",
        "    safety_settings = [{\"category\": c, \"threshold\": \"BLOCK_NONE\"} for c in [\"HARM_CATEGORY_HARASSMENT\", \"HARM_CATEGORY_HATE_SPEECH\", \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"HARM_CATEGORY_DANGEROUS_CONTENT\"]]\n",
        "    while attempts < max_retries:\n",
        "        try:\n",
        "            response = model.generate_content(augmented_prompt, generation_config=generation_config, safety_settings=safety_settings)\n",
        "            if not response.parts:\n",
        "                 block_reason = response.prompt_feedback.block_reason if hasattr(response, 'prompt_feedback') and response.prompt_feedback else \"Desconhecida\"\n",
        "                 finish_reason = response.candidates[0].finish_reason if hasattr(response, 'candidates') and response.candidates else \"Desconhecido\"\n",
        "                 if finish_reason != 'STOP':\n",
        "                     print(f\"Aviso: Resposta bloqueada LOTE RAG. Razão: {block_reason} / Finish: {finish_reason}\")\n",
        "                     return [f\"Bloqueado ({block_reason})\" for _ in range(batch_size)]\n",
        "                 else:\n",
        "                     print(\"Aviso: Resposta vazia LOTE RAG (Finish Reason STOP).\")\n",
        "                     return [\"Erro: Resposta Vazia no Lote\" for _ in range(batch_size)]\n",
        "            ai_answers_raw = response.text\n",
        "            parsed_answers = parse_ai_batch_response(ai_answers_raw, batch_size)\n",
        "            return parsed_answers\n",
        "        except Exception as e:\n",
        "            attempts += 1; print(f\"Erro API Gemini LOTE RAG (Tentativa {attempts}/{max_retries}): {e}\")\n",
        "            wait_time = 2 ** attempts\n",
        "            if \"429\" in str(e) or \"resource_exhausted\" in str(e).lower(): wait_time = max(wait_time, 10); print(f\"Rate limit/Recurso Esgotado. Aguardando {wait_time}s...\")\n",
        "            elif attempts < max_retries: print(f\"  Aguardando {wait_time}s...\")\n",
        "            else: print(f\"Falha LOTE RAG após {max_retries} tentativas.\"); return [\"Erro de API\" for _ in range(batch_size)]\n",
        "            time.sleep(wait_time)\n",
        "    return [\"Erro: Máximo de tentativas atingido\" for _ in range(batch_size)]\n",
        "\n",
        "# --- Função Principal de Avaliação (sem alterações da versão RAG anterior) ---\n",
        "def evaluate_questions_with_rag(questions_to_process, faiss_index, text_chunks):\n",
        "    results = []\n",
        "    total_questions = len(questions_to_process)\n",
        "    print(f\"Iniciando avaliação RAG de {total_questions} questões em lotes de {BATCH_SIZE}...\")\n",
        "    if faiss_index is None or not text_chunks:\n",
        "        print(\"ERRO: Índice FAISS ou chunks não disponíveis. Abortando avaliação RAG.\")\n",
        "        return results\n",
        "    for i in range(0, total_questions, BATCH_SIZE):\n",
        "        batch_questions_data = questions_to_process[i:min(i + BATCH_SIZE, total_questions)]\n",
        "        current_batch_size = len(batch_questions_data)\n",
        "        print(f\"\\n--- Processando Lote RAG {i // BATCH_SIZE + 1}/{(total_questions + BATCH_SIZE - 1) // BATCH_SIZE} (Questões {i + 1} a {i + current_batch_size}) ---\")\n",
        "        batch_questions_with_context = []\n",
        "        print(\"  Recuperando contexto RAG para o lote...\")\n",
        "        for q_idx, question_data in enumerate(batch_questions_data):\n",
        "            print(f\"    Recuperando para questão {i+1+q_idx} (ID: {question_data['id']})...\")\n",
        "            query = question_data['enunciado']\n",
        "            retrieved_context = retrieve_relevant_context(query, faiss_index, text_chunks)\n",
        "            batch_questions_with_context.append({'question': question_data, 'context': retrieved_context})\n",
        "            time.sleep(0.1)\n",
        "        print(\"  Formatando prompt aumentado para a IA...\")\n",
        "        augmented_batch_prompt = format_augmented_batch_for_ai(batch_questions_with_context)\n",
        "        print(\"  Enviando lote aumentado para a IA...\")\n",
        "        ai_answers_for_batch = get_ai_answers_for_augmented_batch(augmented_batch_prompt, current_batch_size)\n",
        "        print(\"  Processando respostas do lote...\")\n",
        "        for j, augmented_data in enumerate(batch_questions_with_context):\n",
        "            question_data = augmented_data['question']\n",
        "            if j < len(ai_answers_for_batch):\n",
        "                ai_answer = ai_answers_for_batch[j]\n",
        "                correct_answer = question_data['resposta_correta']\n",
        "                is_valid_ai_answer = not ai_answer.startswith(\"Erro\") and not ai_answer.startswith(\"Bloqueado\")\n",
        "                is_correct = is_valid_ai_answer and (ai_answer == correct_answer)\n",
        "                results.append({'id': question_data['id'], 'enunciado': question_data['enunciado'],\n",
        "                                'resposta_ia': ai_answer, 'resposta_correta': correct_answer,\n",
        "                                'resultado': 'CERTO' if is_correct else ('ERRADO' if is_valid_ai_answer else 'ERRO_IA'),\n",
        "                                'areas_medicas': \", \".join(question_data['areas_medicas']),\n",
        "                                'continha_imagem': question_data['continha_imagem']})\n",
        "            else:\n",
        "                 print(f\"Erro: Resposta ausente para questão {question_data['id']} no lote.\")\n",
        "                 results.append({'id': question_data['id'], 'enunciado': question_data['enunciado'],\n",
        "                                'resposta_ia': 'Erro: Resposta Ausente no Lote',\n",
        "                                'resposta_correta': question_data['resposta_correta'], 'resultado': 'ERRO_IA',\n",
        "                                'areas_medicas': \", \".join(question_data['areas_medicas']),\n",
        "                                'continha_imagem': question_data['continha_imagem']})\n",
        "        if i + BATCH_SIZE < total_questions:\n",
        "            print(f\"--- Fim do Lote RAG. Aguardando {DELAY_BETWEEN_BATCHES} segundos... ---\")\n",
        "            time.sleep(DELAY_BETWEEN_BATCHES)\n",
        "    print(\"\\nAvaliação RAG de todos os lotes concluída.\")\n",
        "    return results\n",
        "\n",
        "# --- Funções de Cálculo de Acurácia e Salvamento (sem alterações) ---\n",
        "def calculate_accuracy(results, areas_of_interest):\n",
        "    total_processed = len(results); total_correct = 0\n",
        "    area_counts = defaultdict(lambda: {'total': 0, 'correct': 0, 'errors': 0})\n",
        "    errors_parsing, errors_api, errors_blocked, errors_total_ia = 0, 0, 0, 0\n",
        "    for result in results:\n",
        "        if result['resultado'] == 'ERRO_IA':\n",
        "            errors_total_ia += 1\n",
        "            if \"Parsing\" in result['resposta_ia'] or \"Ausente\" in result['resposta_ia']: errors_parsing += 1\n",
        "            elif \"API\" in result['resposta_ia'] or \"Erro:\" in result['resposta_ia'] or \"Vazia\" in result['resposta_ia']: errors_api += 1\n",
        "            elif \"Bloqueado\" in result['resposta_ia']: errors_blocked += 1\n",
        "        elif result['resultado'] == 'CERTO': total_correct += 1\n",
        "        question_areas = result['areas_medicas'].split(', '); processed_for_area_calc = set()\n",
        "        for area in question_areas:\n",
        "            if area in areas_of_interest and area not in processed_for_area_calc:\n",
        "                area_counts[area]['total'] += 1\n",
        "                if result['resultado'] == 'CERTO': area_counts[area]['correct'] += 1\n",
        "                elif result['resultado'] == 'ERRO_IA': area_counts[area]['errors'] += 1\n",
        "                processed_for_area_calc.add(area)\n",
        "    overall_accuracy = (total_correct / total_processed * 100) if total_processed > 0 else 0\n",
        "    valid_processed_for_accuracy = total_processed - errors_total_ia\n",
        "    accuracy_excluding_errors = (total_correct / valid_processed_for_accuracy * 100) if valid_processed_for_accuracy > 0 else 0\n",
        "    area_accuracy = {}\n",
        "    for area, counts in area_counts.items():\n",
        "        valid_area_processed = counts['total'] - counts['errors']\n",
        "        area_accuracy[area] = (counts['correct'] / valid_area_processed * 100) if valid_area_processed > 0 else 0\n",
        "    summary = {'total_questions_processed': total_processed, 'total_correct': total_correct,\n",
        "               'overall_accuracy': overall_accuracy, 'accuracy_excluding_errors': accuracy_excluding_errors,\n",
        "               'area_accuracy': area_accuracy, 'area_counts': area_counts, 'errors_parsing': errors_parsing,\n",
        "               'errors_api': errors_api, 'errors_blocked': errors_blocked, 'errors_total_ia': errors_total_ia,\n",
        "               'valid_processed_for_accuracy': valid_processed_for_accuracy}\n",
        "    return summary\n",
        "\n",
        "def save_results_to_csv(results, filepath):\n",
        "    if not results: print(\"Nenhum resultado para salvar.\"); return\n",
        "    try:\n",
        "        df = pd.DataFrame(results)\n",
        "        cols = ['id', 'enunciado', 'resposta_ia', 'resposta_correta', 'resultado', 'areas_medicas', 'continha_imagem']\n",
        "        df = df.reindex(columns=cols, fill_value='')\n",
        "        df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
        "        print(f\"Resultados salvos com sucesso em '{filepath}' no Google Drive.\")\n",
        "    except IOError: print(f\"Erro ao escrever CSV '{filepath}'. Verifique permissões.\")\n",
        "    except Exception as e: print(f\"Erro inesperado ao salvar CSV: {e}\")\n",
        "\n",
        "# --- Nova Função para Salvar Log ---\n",
        "def save_summary_log(log_filepath, summary, rag_info):\n",
        "    \"\"\"Salva um resumo da execução em um arquivo de log de texto.\"\"\"\n",
        "    try:\n",
        "        with open(log_filepath, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"--- Log de Execução da Avaliação de IA ---\\n\")\n",
        "            f.write(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"Arquivo de Questões: {JSON_FILE_PATH}\\n\")\n",
        "            f.write(f\"Modelo IA: {GEMINI_MODEL_NAME}\\n\")\n",
        "            f.write(f\"Temperatura IA: {AI_TEMPERATURE}\\n\")\n",
        "            f.write(f\"Tamanho do Lote (Batch Size): {BATCH_SIZE}\\n\")\n",
        "            f.write(f\"Máximo de Questões Processadas: {summary['total_questions_processed']} (Limite configurado: {MAX_QUESTIONS_TO_PROCESS})\\n\")\n",
        "            f.write(f\"Áreas Filtradas: {', '.join(AREAS_TO_FILTER)}\\n\")\n",
        "            f.write(\"\\n--- Fonte de Conhecimento RAG ---\\n\")\n",
        "            f.write(rag_info + \"\\n\") # Informação sobre PDFs ou índice carregado\n",
        "            f.write(f\"Chunks: {len(pdf_text_chunks) if pdf_text_chunks else 'N/A'}\\n\")\n",
        "            f.write(f\"Top K Recuperação: {TOP_K_RAG}\\n\")\n",
        "            f.write(\"\\n--- Resumo dos Resultados ---\\n\")\n",
        "            f.write(f\"Total de Acertos: {summary['total_correct']}\\n\")\n",
        "            f.write(f\"Total de Erros da IA: {summary['errors_total_ia']}\\n\")\n",
        "            f.write(f\"  - Erros de Parsing/Ausente: {summary['errors_parsing']}\\n\")\n",
        "            f.write(f\"  - Erros de API/Outros: {summary['errors_api']}\\n\")\n",
        "            f.write(f\"  - Respostas Bloqueadas: {summary['errors_blocked']}\\n\")\n",
        "            f.write(f\"Questões Válidas para Acurácia: {summary['valid_processed_for_accuracy']}\\n\")\n",
        "            f.write(f\"Acurácia Geral (sobre todas): {summary['overall_accuracy']:.2f}%\\n\")\n",
        "            f.write(f\"Acurácia (excluindo erros IA): {summary['accuracy_excluding_errors']:.2f}%\\n\")\n",
        "            f.write(\"\\nAcurácia por Área Médica (sobre válidas):\\n\")\n",
        "            if summary['area_counts']:\n",
        "                for area in AREAS_TO_FILTER:\n",
        "                     if area in summary['area_counts']:\n",
        "                         counts = summary['area_counts'][area]\n",
        "                         acc = summary['area_accuracy'].get(area, 0)\n",
        "                         valid_area_proc = counts['total'] - counts['errors']\n",
        "                         f.write(f\"  - {area}: {acc:.2f}% ({counts['correct']} de {valid_area_proc} válidas / {counts['total']} total / {counts['errors']} erros IA)\\n\")\n",
        "                     else: f.write(f\"  - {area}: Nenhuma questão processada.\\n\")\n",
        "            else: f.write(\"  Nenhuma questão encontrada para as áreas.\\n\")\n",
        "            f.write(\"\\n--- Fim do Log ---\\n\")\n",
        "        print(f\"Log de resumo salvo com sucesso em '{log_filepath}'\")\n",
        "    except IOError:\n",
        "        print(f\"Erro: Não foi possível escrever no arquivo de log '{log_filepath}'. Verifique permissões.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro inesperado ao salvar log: {e}\")\n",
        "\n",
        "\n",
        "# @title 6. Setup RAG (Carregar PDFs ou Índice Salvo) - Execute esta célula UMA VEZ por sessão ou se os PDFs mudarem\n",
        "\n",
        "# --- Variáveis Globais para RAG ---\n",
        "pdf_text_chunks = None\n",
        "faiss_index = None\n",
        "rag_source_info = \"Nenhuma fonte RAG processada ainda.\" # Para o log\n",
        "processed_pdf_files = [] # Para o log\n",
        "# ---------------------------------\n",
        "\n",
        "print(\"--- Iniciando Setup RAG (com Persistência) ---\")\n",
        "\n",
        "# Tenta carregar o índice e os chunks salvos\n",
        "try:\n",
        "    if os.path.exists(FAISS_INDEX_PATH) and os.path.exists(TEXT_CHUNKS_PATH):\n",
        "        print(f\"Carregando índice FAISS de {FAISS_INDEX_PATH}...\")\n",
        "        faiss_index = faiss.read_index(FAISS_INDEX_PATH)\n",
        "        print(f\"Carregando chunks de texto de {TEXT_CHUNKS_PATH}...\")\n",
        "        with open(TEXT_CHUNKS_PATH, 'rb') as f:\n",
        "            pdf_text_chunks = pickle.load(f)\n",
        "        if faiss_index is not None and pdf_text_chunks is not None and len(pdf_text_chunks) > 0 and faiss_index.ntotal == len(pdf_text_chunks):\n",
        "             print(f\"Índice ({faiss_index.ntotal} vetores) e Chunks ({len(pdf_text_chunks)}) carregados com sucesso.\")\n",
        "             rag_source_info = f\"Índice e chunks carregados de {INDEXES_DIR}\" # Atualiza info para log\n",
        "             print(\"--- Setup RAG Concluído (a partir de arquivos salvos) ---\")\n",
        "        else:\n",
        "             print(\"Arquivos de índice/chunks encontrados, mas inválidos ou inconsistentes. Recriando...\")\n",
        "             pdf_text_chunks = None; faiss_index = None\n",
        "             raise FileNotFoundError(\"Inconsistência nos arquivos salvos.\")\n",
        "    else:\n",
        "        print(\"Arquivos de índice/chunks não encontrados. Iniciando criação do zero...\")\n",
        "        raise FileNotFoundError(\"Arquivos de índice/chunks não encontrados.\")\n",
        "\n",
        "except (FileNotFoundError, EOFError, pickle.UnpicklingError, Exception) as load_error:\n",
        "    print(f\"Não foi possível carregar arquivos salvos ou eles não existem/são inválidos ({load_error}). Criando RAG do zero...\")\n",
        "    pdf_text_chunks = None\n",
        "    faiss_index = None\n",
        "    processed_pdf_files = [] # Reseta a lista de arquivos\n",
        "\n",
        "    # 1. Carregar e dividir PDFs do diretório\n",
        "    pdf_text_chunks, processed_pdf_files = load_and_split_pdfs_from_directory(KNOWLEDGE_BASE_DIR)\n",
        "\n",
        "    if pdf_text_chunks:\n",
        "        # 2. Gerar Embeddings\n",
        "        pdf_embeddings = generate_embeddings(pdf_text_chunks)\n",
        "        if pdf_embeddings is not None and len(pdf_embeddings) == len(pdf_text_chunks):\n",
        "            # 3. Criar Índice FAISS\n",
        "            faiss_index = create_faiss_index(pdf_embeddings)\n",
        "            if faiss_index:\n",
        "                # 4. Salvar o índice e os chunks\n",
        "                try:\n",
        "                    os.makedirs(os.path.dirname(FAISS_INDEX_PATH), exist_ok=True)\n",
        "                    print(f\"Salvando índice FAISS em {FAISS_INDEX_PATH}...\")\n",
        "                    faiss.write_index(faiss_index, FAISS_INDEX_PATH)\n",
        "                    print(f\"Salvando chunks de texto em {TEXT_CHUNKS_PATH}...\")\n",
        "                    with open(TEXT_CHUNKS_PATH, 'wb') as f: pickle.dump(pdf_text_chunks, f)\n",
        "                    print(\"Índice e Chunks salvos com sucesso.\")\n",
        "                    rag_source_info = f\"Índice criado a partir dos PDFs: {', '.join(processed_pdf_files)}\" # Atualiza info para log\n",
        "                    print(\"--- Setup RAG Concluído (criado do zero e salvo) ---\")\n",
        "                except Exception as save_error:\n",
        "                    print(f\"Erro ao salvar índice/chunks: {save_error}. RAG funcionará nesta sessão, mas precisará ser recriado.\")\n",
        "                    rag_source_info = f\"Índice criado (erro ao salvar) a partir dos PDFs: {', '.join(processed_pdf_files)}\"\n",
        "            else:\n",
        "                print(\"--- Falha ao criar índice FAISS ---\")\n",
        "                pdf_text_chunks = None; rag_source_info = \"Falha ao criar índice FAISS.\"\n",
        "        else:\n",
        "            print(f\"--- Falha ao gerar embeddings. ---\")\n",
        "            pdf_text_chunks = None; rag_source_info = \"Falha ao gerar embeddings.\"\n",
        "    else:\n",
        "        print(f\"--- Falha ao carregar/processar PDFs de {KNOWLEDGE_BASE_DIR}. O RAG não será utilizado. ---\")\n",
        "        rag_source_info = f\"Falha ao carregar PDFs de {KNOWLEDGE_BASE_DIR}.\"\n",
        "\n",
        "\n",
        "# @title 7. Execução Principal da Avaliação com RAG\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- Iniciando Script de Avaliação com RAG (Múltiplos PDFs e Persistência) ---\")\n",
        "\n",
        "    # Gera o timestamp para os nomes dos arquivos de saída\n",
        "    timestamp_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
        "    output_csv_path_ts = os.path.join(RESULTS_DIR, f\"{BASE_CSV_FILENAME}_{timestamp_str}.csv\")\n",
        "    output_log_path_ts = os.path.join(RESULTS_DIR, f\"{BASE_LOG_FILENAME}_{timestamp_str}.txt\")\n",
        "\n",
        "    if 'API_KEY' not in locals() or not API_KEY:\n",
        "        print(\"!!! ERRO CRÍTICO: API Key não configurada. Interrompendo. !!!\")\n",
        "    elif faiss_index is None or pdf_text_chunks is None:\n",
        "         print(\"!!! ERRO CRÍTICO: Setup RAG não foi concluído com sucesso. Execute a célula '6. Setup RAG' primeiro. Interrompendo. !!!\")\n",
        "    else:\n",
        "        print(\"\\nCarregando dados do JSON...\")\n",
        "        all_data = load_json_data(JSON_FILE_PATH)\n",
        "\n",
        "        if all_data:\n",
        "            print(f\"Total de questões no arquivo: {len(all_data)}\")\n",
        "            print(f\"Filtrando por áreas: {', '.join(AREAS_TO_FILTER)}...\")\n",
        "            filtered_data = filter_questions(all_data, AREAS_TO_FILTER)\n",
        "            print(f\"Número de questões filtradas: {len(filtered_data)}\")\n",
        "\n",
        "            if not filtered_data:\n",
        "                print(\"Nenhuma questão encontrada para as áreas especificadas.\")\n",
        "            else:\n",
        "                questions_to_process = filtered_data\n",
        "                # Limita o número de questões se necessário\n",
        "                if MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0 and MAX_QUESTIONS_TO_PROCESS < len(filtered_data):\n",
        "                    print(f\"Limitando o processamento às primeiras {MAX_QUESTIONS_TO_PROCESS} questões filtradas.\")\n",
        "                    questions_to_process = filtered_data[:MAX_QUESTIONS_TO_PROCESS]\n",
        "                elif MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0:\n",
        "                     print(f\"Processando todas as {len(filtered_data)} questões filtradas.\")\n",
        "                elif MAX_QUESTIONS_TO_PROCESS == 0:\n",
        "                    print(\"MAX_QUESTIONS_TO_PROCESS definido como 0. Nenhuma questão será processada.\")\n",
        "                    questions_to_process = []\n",
        "                else: # MAX_QUESTIONS_TO_PROCESS é None\n",
        "                    print(f\"Processando todas as {len(filtered_data)} questões filtradas.\")\n",
        "\n",
        "                if questions_to_process:\n",
        "                    # Avalia as questões USANDO RAG\n",
        "                    evaluation_results = evaluate_questions_with_rag(questions_to_process, faiss_index, pdf_text_chunks)\n",
        "\n",
        "                    if evaluation_results:\n",
        "                        accuracy_summary = calculate_accuracy(evaluation_results, AREAS_TO_FILTER)\n",
        "                        # Salva CSV e Log com timestamp\n",
        "                        save_results_to_csv(evaluation_results, output_csv_path_ts)\n",
        "                        save_summary_log(output_log_path_ts, accuracy_summary, rag_source_info)\n",
        "\n",
        "                        # Mostra o resumo da acurácia (igual ao log)\n",
        "                        print(\"\\n--- Resumo da Avaliação (com RAG de Múltiplos PDFs) ---\")\n",
        "                        print(f\"Modelo IA Utilizado: {GEMINI_MODEL_NAME}\")\n",
        "                        print(f\"Temperatura Utilizada: {AI_TEMPERATURE}\")\n",
        "                        print(f\"Fonte de Conhecimento RAG: {rag_source_info}\")\n",
        "                        print(f\"Total de Questões Processadas: {accuracy_summary['total_questions_processed']}\")\n",
        "                        print(f\"Total de Acertos: {accuracy_summary['total_correct']}\")\n",
        "                        print(f\"Total de Erros da IA: {accuracy_summary['errors_total_ia']}\")\n",
        "                        print(f\"  - Erros de Parsing/Ausente: {accuracy_summary['errors_parsing']}\")\n",
        "                        print(f\"  - Erros de API/Outros: {accuracy_summary['errors_api']}\")\n",
        "                        print(f\"  - Respostas Bloqueadas: {accuracy_summary['errors_blocked']}\")\n",
        "                        print(f\"Questões Válidas para Acurácia: {accuracy_summary['valid_processed_for_accuracy']}\")\n",
        "                        print(f\"\\nAcurácia Geral (sobre todas): {accuracy_summary['overall_accuracy']:.2f}%\")\n",
        "                        print(f\"Acurácia (excluindo erros IA): {accuracy_summary['accuracy_excluding_errors']:.2f}%\")\n",
        "                        print(\"\\nAcurácia por Área Médica (sobre válidas):\")\n",
        "                        if accuracy_summary['area_counts']:\n",
        "                            for area in AREAS_TO_FILTER:\n",
        "                                 if area in accuracy_summary['area_counts']:\n",
        "                                     counts = accuracy_summary['area_counts'][area]\n",
        "                                     acc = accuracy_summary['area_accuracy'].get(area, 0)\n",
        "                                     valid_area_proc = counts['total'] - counts['errors']\n",
        "                                     print(f\"  - {area}: {acc:.2f}% ({counts['correct']} de {valid_area_proc} válidas / {counts['total']} total / {counts['errors']} erros IA)\")\n",
        "                                 else: print(f\"  - {area}: Nenhuma questão processada.\")\n",
        "                        else: print(\"  Nenhuma questão encontrada para as áreas.\")\n",
        "                        print(f\"\\nResultados detalhados salvos em: {output_csv_path_ts}\")\n",
        "                        print(f\"Log de resumo salvo em: {output_log_path_ts}\")\n",
        "                    else: print(\"Avaliação RAG não produziu resultados.\")\n",
        "                else: print(\"Nenhuma questão selecionada para processamento.\")\n",
        "        else: print(\"Não foi possível carregar os dados do JSON.\")\n",
        "\n",
        "    print(\"\\n--- Fim do Script ---\")"
      ]
    }
  ]
}