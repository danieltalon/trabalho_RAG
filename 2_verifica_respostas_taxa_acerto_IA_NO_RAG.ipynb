{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNccHbPlnUbm8HoOf9lpiMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danieltalon/trabalho_RAG/blob/main/2_verifica_respostas_taxa_acerto_IA_NO_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "kIrpKyal8dAR",
        "outputId": "4adb07ae-bd51-48ee-92cf-5f52e0d6d2b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado com sucesso!\n",
            "API Key do Google configurada com sucesso via Colab Secrets.\n",
            "--- Iniciando Script de Avaliação (Processamento em Lote para IA) ---\n",
            "\n",
            "Carregando dados do JSON...\n",
            "Total de questões no arquivo: 670\n",
            "Filtrando por áreas: Ginecologia, Obstetrícia, Pediatria...\n",
            "Número de questões filtradas: 209\n",
            "Processando todas as 209 questões filtradas (MAX_QUESTIONS_TO_PROCESS >= total filtrado).\n",
            "Iniciando avaliação de 209 questões em lotes de 25...\n",
            "\n",
            "--- Processando Lote 1/9 (Questões 1 a 25) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 2/9 (Questões 26 a 50) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 3/9 (Questões 51 a 75) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 4/9 (Questões 76 a 100) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 5/9 (Questões 101 a 125) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 6/9 (Questões 126 a 150) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 7/9 (Questões 151 a 175) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 8/9 (Questões 176 a 200) ---\n",
            "--- Fim do Lote. Aguardando 5 segundos antes da próxima chamada à API... ---\n",
            "\n",
            "--- Processando Lote 9/9 (Questões 201 a 209) ---\n",
            "\n",
            "Avaliação de todos os lotes concluída.\n",
            "Resultados salvos com sucesso em '/content/drive/MyDrive/resultados_avaliacao_ia_lote.csv' no Google Drive.\n",
            "\n",
            "--- Resumo da Avaliação ---\n",
            "Modelo IA Utilizado: gemini-1.5-flash\n",
            "Total de Questões Processadas: 209\n",
            "Total de Acertos: 142\n",
            "Total de Erros da IA (API/Parsing/Bloqueio/Ausente): 0\n",
            "  - Erros de Parsing/Ausente no Lote: 0\n",
            "  - Erros de API/Outros: 0\n",
            "  - Respostas Bloqueadas: 0\n",
            "Questões Válidas para Cálculo de Acurácia (sem erros IA): 209\n",
            "\n",
            "Acurácia Geral (sobre todas processadas): 67.94%\n",
            "Acurácia (excluindo erros da IA): 67.94%\n",
            "\n",
            "Acurácia por Área Médica (calculada sobre questões válidas para cada área):\n",
            "  - Ginecologia: 68.13% (62 de 91 válidas / 91 total / 0 erros IA)\n",
            "  - Obstetrícia: 68.52% (37 de 54 válidas / 54 total / 0 erros IA)\n",
            "  - Pediatria: 69.81% (74 de 106 válidas / 106 total / 0 erros IA)\n",
            "\n",
            "Resultados detalhados salvos em: /content/drive/MyDrive/resultados_avaliacao_ia_lote.csv\n",
            "\n",
            "--- Fim do Script ---\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Avaliação de IA em Questões Médicas (Adaptado para Google Colab - COM BATCH API)\n",
        "\n",
        "Este script avalia o desempenho de um modelo de IA generativa (Google Gemini)\n",
        "em responder questões de múltipla escolha de provas de medicina,\n",
        "filtradas por áreas específicas, enviando perguntas em lotes para a API.\n",
        "\"\"\"\n",
        "\n",
        "# @title 1. Instalar Bibliotecas e Importar Módulos Necessários\n",
        "# Instala as bibliotecas necessárias no ambiente Colab\n",
        "%pip install -q google-generativeai pandas # Pandas é útil para manipulação de dados e CSV\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, drive, files # Módulos específicos do Colab\n",
        "from collections import defaultdict\n",
        "import io # Para lidar com arquivos carregados\n",
        "\n",
        "# @title 2. Definir Constantes e Configurações\n",
        "\n",
        "# --- Constantes de Configuração ---\n",
        "\n",
        "# Caminho para o arquivo JSON no Google Drive (AJUSTE CONFORME NECESSÁRIO)\n",
        "JSON_FILE_PATH = '/content/questoes_2021_2022_2023_2024_limit700_classificadas_lote.json'\n",
        "\n",
        "# Caminho para salvar o arquivo CSV de resultados no Google Drive (AJUSTE CONFORME NECESSÁRIO)\n",
        "OUTPUT_CSV_FILE = '/content/drive/MyDrive/resultados_avaliacao_ia_lote.csv'\n",
        "\n",
        "# Áreas médicas para filtrar as questões (Case-sensitive)\n",
        "AREAS_TO_FILTER = [\"Ginecologia\", \"Obstetrícia\", \"Pediatria\"]\n",
        "\n",
        "# Parâmetros de Processamento\n",
        "BATCH_SIZE = 25\n",
        "DELAY_BETWEEN_BATCHES = 5\n",
        "MAX_RETRIES = 3\n",
        "# Defina None ou um número maior que o total de questões filtradas para processar todas\n",
        "MAX_QUESTIONS_TO_PROCESS = 700\n",
        "\n",
        "# Modelo Gemini a ser usado\n",
        "GEMINI_MODEL_NAME = 'gemini-1.5-flash'\n",
        "\n",
        "# Nome da chave secreta no Colab para a API Key do Google\n",
        "COLAB_SECRET_KEY_NAME = 'GOOGLE_API_KEY'\n",
        "#-------------------------------------\n",
        "\n",
        "# @title 3. Montar Google Drive (Necessário para acessar/salvar arquivos)\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive montado com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao montar Google Drive: {e}\")\n",
        "    print(\"Certifique-se de autorizar o acesso quando solicitado.\")\n",
        "    # exit()\n",
        "\n",
        "# @title 4. Configurar API Key do Google (Usando Colab Secrets)\n",
        "try:\n",
        "    API_KEY = userdata.get(COLAB_SECRET_KEY_NAME)\n",
        "    if not API_KEY:\n",
        "        raise ValueError(f\"Chave secreta '{COLAB_SECRET_KEY_NAME}' não encontrada ou vazia.\")\n",
        "    genai.configure(api_key=API_KEY)\n",
        "    print(\"API Key do Google configurada com sucesso via Colab Secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao configurar a API Key: {e}\")\n",
        "    print(f\"Verifique se você adicionou a chave '{COLAB_SECRET_KEY_NAME}' nos Secrets do Colab.\")\n",
        "    # exit()\n",
        "\n",
        "# @title 5. Funções Auxiliares (Carregar, Filtrar, Formatar LOTE, Chamar IA em LOTE, Parsear LOTE, Avaliar, Salvar)\n",
        "\n",
        "def load_json_data(filepath):\n",
        "    \"\"\"Carrega os dados do arquivo JSON.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo JSON não encontrado em '{filepath}'. Verifique o caminho no Google Drive.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Erro: Falha ao decodificar o arquivo JSON '{filepath}'\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Erro inesperado ao carregar o JSON: {e}\")\n",
        "        return None\n",
        "\n",
        "def filter_questions(data, areas):\n",
        "    \"\"\"Filtra as questões pelas áreas médicas especificadas.\"\"\"\n",
        "    filtered = []\n",
        "    if not data:\n",
        "        return filtered\n",
        "    seen_ids = set()\n",
        "    for i, question in enumerate(data):\n",
        "        prova = question.get('prova', 'unk_prova')\n",
        "        numero = question.get('numero', f'idx_{i}')\n",
        "        question_id = f\"{prova}_{numero}\"\n",
        "        if question_id in seen_ids:\n",
        "            continue\n",
        "        question_areas = question.get('areas_medicas', [])\n",
        "        if any(area in question_areas for area in areas):\n",
        "            if 'enunciado' in question and 'alternativas' in question and 'resposta' in question:\n",
        "                if isinstance(question['alternativas'], dict):\n",
        "                    filtered.append({\n",
        "                        'id': question_id,\n",
        "                        'enunciado': question['enunciado'],\n",
        "                        'alternativas': question['alternativas'],\n",
        "                        'resposta_correta': str(question['resposta']).strip().upper(),\n",
        "                        'areas_medicas': question_areas,\n",
        "                        'continha_imagem': question.get('contains_img', False)\n",
        "                    })\n",
        "                    seen_ids.add(question_id)\n",
        "                else:\n",
        "                    print(f\"Aviso: Alternativas inválidas para a questão ID {question_id}. Pulando.\")\n",
        "            else:\n",
        "                print(f\"Aviso: Questão ID {question_id} faltando campos essenciais. Pulando.\")\n",
        "    return filtered\n",
        "\n",
        "def format_batch_for_ai(batch_questions):\n",
        "    \"\"\"Formata um LOTE de questões para um único prompt da IA.\"\"\"\n",
        "    prompt = \"Responda às seguintes questões de múltipla escolha. Para cada questão, forneça APENAS a letra da alternativa correta, precedida pelo número da questão no lote e um ponto (ex: 1. A, 2. C, 3. B).\\n\\n\"\n",
        "    for i, question_data in enumerate(batch_questions):\n",
        "        prompt += f\"--- Questão {i+1} ---\\n\"\n",
        "        prompt += f\"Enunciado: {question_data['enunciado']}\\n\\nAlternativas:\\n\"\n",
        "        alternatives = question_data['alternativas']\n",
        "        try:\n",
        "            sorted_keys = sorted(alternatives.keys())\n",
        "        except TypeError:\n",
        "            sorted_keys = alternatives.keys()\n",
        "        for key in sorted_keys:\n",
        "            prompt += f\"{key}: {alternatives[key]}\\n\"\n",
        "        if question_data['continha_imagem']:\n",
        "            prompt += \"(Observação: Esta questão originalmente continha uma imagem, que não pode ser exibida aqui.)\\n\"\n",
        "        prompt += \"\\n\" # Espaço entre questões\n",
        "    prompt += \"Respostas (formato: 1. Letra, 2. Letra, ...):\\n\"\n",
        "    return prompt\n",
        "\n",
        "def parse_ai_batch_response(response_text, batch_size):\n",
        "    \"\"\"Analisa a resposta da IA para um lote de questões.\"\"\"\n",
        "    answers = {} # Dicionário para armazenar {indice_no_lote: resposta}\n",
        "    if not response_text:\n",
        "        print(\"Aviso: Resposta da IA para o lote está vazia.\")\n",
        "        # Marca todas as questões do lote como erro\n",
        "        for i in range(batch_size):\n",
        "            answers[i] = \"Erro: Resposta Vazia no Lote\"\n",
        "        return answers\n",
        "\n",
        "    # Tenta extrair respostas no formato \"Número. Letra\"\n",
        "    # Regex para encontrar \"Número. Letra\" (com ou sem espaço após o ponto)\n",
        "    pattern = re.compile(r\"^\\s*(\\d+)\\s*\\.\\s*([A-E])\\b\", re.MULTILINE)\n",
        "    found_answers = pattern.findall(response_text.strip().upper())\n",
        "\n",
        "    if found_answers:\n",
        "        for num_str, letter in found_answers:\n",
        "            try:\n",
        "                question_index = int(num_str) - 1 # Ajusta para índice 0-based\n",
        "                if 0 <= question_index < batch_size:\n",
        "                    if question_index not in answers: # Pega a primeira ocorrência para um número\n",
        "                         answers[question_index] = letter\n",
        "                    else:\n",
        "                         print(f\"Aviso: Resposta duplicada para questão {question_index + 1} no lote. Usando a primeira encontrada.\")\n",
        "                else:\n",
        "                    print(f\"Aviso: Índice de questão inválido ({num_str}) encontrado na resposta do lote.\")\n",
        "            except ValueError:\n",
        "                print(f\"Aviso: Não foi possível converter o número da questão '{num_str}' em inteiro.\")\n",
        "    else:\n",
        "        # Se o formato principal falhar, tenta uma abordagem mais simples (ex: A, B, C em linhas separadas)\n",
        "        # Isso é menos confiável e pode exigir ajustes\n",
        "        lines = response_text.strip().split('\\n')\n",
        "        potential_answers = [line.strip() for line in lines if len(line.strip()) == 1 and 'A' <= line.strip().upper() <= 'E']\n",
        "        if len(potential_answers) == batch_size:\n",
        "             print(\"Aviso: Usando formato alternativo de parsing (uma letra por linha).\")\n",
        "             for i, ans in enumerate(potential_answers):\n",
        "                 answers[i] = ans.upper()\n",
        "        else:\n",
        "             print(f\"Aviso: Não foi possível parsear a resposta do lote no formato esperado. Resposta recebida:\\n{response_text}\")\n",
        "\n",
        "\n",
        "    # Preenche as respostas faltantes com erro\n",
        "    for i in range(batch_size):\n",
        "        if i not in answers:\n",
        "            answers[i] = \"Erro de Parsing no Lote\"\n",
        "\n",
        "    # Converte o dicionário para uma lista ordenada pelo índice\n",
        "    answer_list = [answers.get(i, \"Erro: Resposta Ausente no Lote\") for i in range(batch_size)]\n",
        "    return answer_list\n",
        "\n",
        "\n",
        "def get_ai_answers_for_batch(batch_questions, model_name=GEMINI_MODEL_NAME, max_retries=MAX_RETRIES):\n",
        "    \"\"\"Envia um LOTE de questões para a IA e retorna a lista de respostas.\"\"\"\n",
        "    prompt = format_batch_for_ai(batch_questions)\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "    attempts = 0\n",
        "    batch_size = len(batch_questions)\n",
        "\n",
        "    # Configuração de segurança\n",
        "    safety_settings = [\n",
        "        {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "        {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    ]\n",
        "\n",
        "    # Define a configuração de geração com baixa temperatura\n",
        "    generation_config = genai.types.GenerationConfig(\n",
        "        temperature=0.2 # Valor baixo para maior determinismo e precisão\n",
        "        # Outros parâmetros como top_p, top_k podem ser ajustados se necessário,\n",
        "        # mas a temperatura é o principal para este caso.\n",
        "    )\n",
        "\n",
        "\n",
        "    while attempts < max_retries:\n",
        "        try:\n",
        "            # response = model.generate_content(prompt, safety_settings=safety_settings)\n",
        "            response = model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=generation_config,\n",
        "                safety_settings=safety_settings\n",
        "            )\n",
        "\n",
        "            # Verifica bloqueio ou resposta vazia\n",
        "            if not response.parts:\n",
        "                 block_reason = \"Razão Desconhecida\"\n",
        "                 finish_reason = \"Não especificado\"\n",
        "                 if hasattr(response, 'prompt_feedback') and response.prompt_feedback:\n",
        "                     block_reason = response.prompt_feedback.block_reason or block_reason\n",
        "                 if hasattr(response, 'candidates') and response.candidates and hasattr(response.candidates[0], 'finish_reason'):\n",
        "                     finish_reason = response.candidates[0].finish_reason or finish_reason\n",
        "\n",
        "                 if finish_reason != 'STOP':\n",
        "                     print(f\"Aviso: Resposta bloqueada para o LOTE. Razão: {block_reason} / Finish Reason: {finish_reason}\")\n",
        "                     return [f\"Bloqueado ({block_reason})\" for _ in range(batch_size)]\n",
        "                 else:\n",
        "                     print(\"Aviso: Resposta vazia ou sem partes para o LOTE, mas Finish Reason é STOP.\")\n",
        "                     return [\"Erro: Resposta Vazia no Lote\" for _ in range(batch_size)]\n",
        "\n",
        "            ai_answers_raw = response.text\n",
        "            parsed_answers = parse_ai_batch_response(ai_answers_raw, batch_size)\n",
        "            return parsed_answers\n",
        "        except Exception as e:\n",
        "            attempts += 1\n",
        "            print(f\"Erro ao chamar a API Gemini para o LOTE (Tentativa {attempts}/{max_retries}): {e}\")\n",
        "            if attempts < max_retries:\n",
        "                wait_time = 2 ** attempts\n",
        "                print(f\"  Aguardando {wait_time}s antes de tentar novamente...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                print(f\"Falha ao obter resposta para o LOTE após {max_retries} tentativas.\")\n",
        "                return [\"Erro de API\" for _ in range(batch_size)] # Retorna erro para todas no lote\n",
        "\n",
        "    return [\"Erro: Máximo de tentativas atingido\" for _ in range(batch_size)] # Retorna erro para todas\n",
        "\n",
        "def evaluate_questions(questions_to_process):\n",
        "    \"\"\"Processa as questões em lotes, obtém respostas da IA em lote e avalia.\"\"\"\n",
        "    results = []\n",
        "    total_questions = len(questions_to_process)\n",
        "    print(f\"Iniciando avaliação de {total_questions} questões em lotes de {BATCH_SIZE}...\")\n",
        "\n",
        "    for i in range(0, total_questions, BATCH_SIZE):\n",
        "        batch_questions_data = questions_to_process[i:min(i + BATCH_SIZE, total_questions)]\n",
        "        current_batch_size = len(batch_questions_data)\n",
        "        print(f\"\\n--- Processando Lote {i // BATCH_SIZE + 1}/{(total_questions + BATCH_SIZE - 1) // BATCH_SIZE} (Questões {i + 1} a {i + current_batch_size}) ---\")\n",
        "\n",
        "        # Chama a IA UMA VEZ para o lote inteiro\n",
        "        ai_answers_for_batch = get_ai_answers_for_batch(batch_questions_data)\n",
        "\n",
        "        # Processa os resultados para cada questão no lote\n",
        "        for j, question_data in enumerate(batch_questions_data):\n",
        "            ai_answer = ai_answers_for_batch[j] # Pega a resposta correspondente do lote\n",
        "            correct_answer = question_data['resposta_correta']\n",
        "\n",
        "            is_valid_ai_answer = not ai_answer.startswith(\"Erro\") and not ai_answer.startswith(\"Bloqueado\")\n",
        "            is_correct = is_valid_ai_answer and (ai_answer == correct_answer)\n",
        "\n",
        "            results.append({\n",
        "                'id': question_data['id'],\n",
        "                'enunciado': question_data['enunciado'],\n",
        "                'resposta_ia': ai_answer,\n",
        "                'resposta_correta': correct_answer,\n",
        "                'resultado': 'CERTO' if is_correct else ('ERRADO' if is_valid_ai_answer else 'ERRO_IA'),\n",
        "                'areas_medicas': \", \".join(question_data['areas_medicas']),\n",
        "                'continha_imagem': question_data['continha_imagem']\n",
        "            })\n",
        "\n",
        "        # Pausa entre os LOTES de chamadas à API\n",
        "        if i + BATCH_SIZE < total_questions:\n",
        "            print(f\"--- Fim do Lote. Aguardando {DELAY_BETWEEN_BATCHES} segundos antes da próxima chamada à API... ---\")\n",
        "            time.sleep(DELAY_BETWEEN_BATCHES)\n",
        "\n",
        "    print(\"\\nAvaliação de todos os lotes concluída.\")\n",
        "    return results\n",
        "\n",
        "# Função calculate_accuracy (sem alterações, já calcula com base nos resultados individuais)\n",
        "def calculate_accuracy(results, areas_of_interest):\n",
        "    \"\"\"Calcula a acurácia geral e por área médica.\"\"\"\n",
        "    total_processed = len(results)\n",
        "    total_correct = 0\n",
        "    area_counts = defaultdict(lambda: {'total': 0, 'correct': 0, 'errors': 0})\n",
        "    errors_parsing = 0\n",
        "    errors_api = 0\n",
        "    errors_blocked = 0\n",
        "    errors_total_ia = 0\n",
        "\n",
        "    for result in results:\n",
        "        is_error = False\n",
        "        if result['resultado'] == 'ERRO_IA':\n",
        "            errors_total_ia += 1\n",
        "            is_error = True\n",
        "            # Detalha o tipo de erro\n",
        "            if \"Parsing\" in result['resposta_ia']:\n",
        "                errors_parsing += 1\n",
        "            elif \"API\" in result['resposta_ia'] or \"Erro:\" in result['resposta_ia']:\n",
        "                 errors_api += 1\n",
        "            elif \"Bloqueado\" in result['resposta_ia']:\n",
        "                 errors_blocked += 1\n",
        "            elif \"Ausente\" in result['resposta_ia']: # Erro específico do parsing de lote\n",
        "                 errors_parsing += 1 # Ou pode criar uma categoria nova\n",
        "            elif \"Vazia\" in result['resposta_ia']:\n",
        "                 errors_api +=1 # Ou categoria nova\n",
        "        elif result['resultado'] == 'CERTO':\n",
        "            total_correct += 1\n",
        "\n",
        "        # Calcula acurácia por área\n",
        "        question_areas = result['areas_medicas'].split(', ')\n",
        "        processed_for_area_calc = set()\n",
        "        for area in question_areas:\n",
        "            if area in areas_of_interest and area not in processed_for_area_calc:\n",
        "                area_counts[area]['total'] += 1\n",
        "                if result['resultado'] == 'CERTO':\n",
        "                    area_counts[area]['correct'] += 1\n",
        "                elif result['resultado'] == 'ERRO_IA':\n",
        "                     area_counts[area]['errors'] += 1\n",
        "                processed_for_area_calc.add(area)\n",
        "\n",
        "    overall_accuracy = (total_correct / total_processed * 100) if total_processed > 0 else 0\n",
        "    valid_processed_for_accuracy = total_processed - errors_total_ia\n",
        "    accuracy_excluding_errors = (total_correct / valid_processed_for_accuracy * 100) if valid_processed_for_accuracy > 0 else 0\n",
        "\n",
        "    area_accuracy = {}\n",
        "    for area, counts in area_counts.items():\n",
        "        valid_area_processed = counts['total'] - counts['errors']\n",
        "        area_accuracy[area] = (counts['correct'] / valid_area_processed * 100) if valid_area_processed > 0 else 0\n",
        "\n",
        "    summary = {\n",
        "        'total_questions_processed': total_processed,\n",
        "        'total_correct': total_correct,\n",
        "        'overall_accuracy': overall_accuracy,\n",
        "        'accuracy_excluding_errors': accuracy_excluding_errors,\n",
        "        'area_accuracy': area_accuracy,\n",
        "        'area_counts': area_counts,\n",
        "        'errors_parsing': errors_parsing,\n",
        "        'errors_api': errors_api,\n",
        "        'errors_blocked': errors_blocked,\n",
        "        'errors_total_ia': errors_total_ia,\n",
        "        'valid_processed_for_accuracy': valid_processed_for_accuracy\n",
        "    }\n",
        "    return summary\n",
        "\n",
        "# Função save_results_to_csv (sem alterações)\n",
        "def save_results_to_csv(results, filepath):\n",
        "    \"\"\"Salva os resultados detalhados em um arquivo CSV usando Pandas.\"\"\"\n",
        "    if not results:\n",
        "        print(\"Nenhum resultado para salvar.\")\n",
        "        return\n",
        "    try:\n",
        "        df = pd.DataFrame(results)\n",
        "        cols = ['id', 'enunciado', 'resposta_ia', 'resposta_correta', 'resultado', 'areas_medicas', 'continha_imagem']\n",
        "        df = df.reindex(columns=cols, fill_value='')\n",
        "        df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
        "        print(f\"Resultados salvos com sucesso em '{filepath}' no Google Drive.\")\n",
        "    except IOError:\n",
        "        print(f\"Erro: Não foi possível escrever no arquivo CSV '{filepath}'. Verifique o caminho e as permissões no Google Drive.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro inesperado ao salvar CSV com Pandas: {e}\")\n",
        "\n",
        "# @title 6. Execução Principal do Script\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Iniciando Script de Avaliação (Processamento em Lote para IA) ---\")\n",
        "\n",
        "    if 'API_KEY' not in locals() or not API_KEY:\n",
        "        print(\"!!! ERRO CRÍTICO: API Key não configurada. Interrompendo. !!!\")\n",
        "    else:\n",
        "        print(\"\\nCarregando dados do JSON...\")\n",
        "        all_data = load_json_data(JSON_FILE_PATH)\n",
        "\n",
        "        if all_data:\n",
        "            print(f\"Total de questões no arquivo: {len(all_data)}\")\n",
        "            print(f\"Filtrando por áreas: {', '.join(AREAS_TO_FILTER)}...\")\n",
        "            filtered_data = filter_questions(all_data, AREAS_TO_FILTER)\n",
        "            print(f\"Número de questões filtradas: {len(filtered_data)}\")\n",
        "\n",
        "            if not filtered_data:\n",
        "                print(\"Nenhuma questão encontrada para as áreas especificadas.\")\n",
        "            else:\n",
        "                questions_to_process = filtered_data\n",
        "                if MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0 and MAX_QUESTIONS_TO_PROCESS < len(filtered_data):\n",
        "                    print(f\"Limitando o processamento às primeiras {MAX_QUESTIONS_TO_PROCESS} questões filtradas.\")\n",
        "                    questions_to_process = filtered_data[:MAX_QUESTIONS_TO_PROCESS]\n",
        "                elif MAX_QUESTIONS_TO_PROCESS is not None and MAX_QUESTIONS_TO_PROCESS > 0:\n",
        "                     print(f\"Processando todas as {len(filtered_data)} questões filtradas (MAX_QUESTIONS_TO_PROCESS >= total filtrado).\")\n",
        "                elif MAX_QUESTIONS_TO_PROCESS == 0:\n",
        "                    print(\"MAX_QUESTIONS_TO_PROCESS definido como 0. Nenhuma questão será processada.\")\n",
        "                    questions_to_process = []\n",
        "                else: # MAX_QUESTIONS_TO_PROCESS é None\n",
        "                    print(f\"Processando todas as {len(filtered_data)} questões filtradas (MAX_QUESTIONS_TO_PROCESS não definido).\")\n",
        "\n",
        "                if questions_to_process:\n",
        "                    evaluation_results = evaluate_questions(questions_to_process)\n",
        "                    accuracy_summary = calculate_accuracy(evaluation_results, AREAS_TO_FILTER)\n",
        "                    save_results_to_csv(evaluation_results, OUTPUT_CSV_FILE)\n",
        "\n",
        "                    # Mostra o resumo da acurácia\n",
        "                    print(\"\\n--- Resumo da Avaliação ---\")\n",
        "                    print(f\"Modelo IA Utilizado: {GEMINI_MODEL_NAME}\")\n",
        "                    print(f\"Total de Questões Processadas: {accuracy_summary['total_questions_processed']}\")\n",
        "                    print(f\"Total de Acertos: {accuracy_summary['total_correct']}\")\n",
        "                    print(f\"Total de Erros da IA (API/Parsing/Bloqueio/Ausente): {accuracy_summary['errors_total_ia']}\")\n",
        "                    print(f\"  - Erros de Parsing/Ausente no Lote: {accuracy_summary['errors_parsing']}\")\n",
        "                    print(f\"  - Erros de API/Outros: {accuracy_summary['errors_api']}\")\n",
        "                    print(f\"  - Respostas Bloqueadas: {accuracy_summary['errors_blocked']}\")\n",
        "                    print(f\"Questões Válidas para Cálculo de Acurácia (sem erros IA): {accuracy_summary['valid_processed_for_accuracy']}\")\n",
        "                    print(f\"\\nAcurácia Geral (sobre todas processadas): {accuracy_summary['overall_accuracy']:.2f}%\")\n",
        "                    print(f\"Acurácia (excluindo erros da IA): {accuracy_summary['accuracy_excluding_errors']:.2f}%\")\n",
        "\n",
        "                    print(\"\\nAcurácia por Área Médica (calculada sobre questões válidas para cada área):\")\n",
        "                    if accuracy_summary['area_counts']:\n",
        "                        for area in AREAS_TO_FILTER:\n",
        "                             if area in accuracy_summary['area_counts']:\n",
        "                                 counts = accuracy_summary['area_counts'][area]\n",
        "                                 acc = accuracy_summary['area_accuracy'].get(area, 0)\n",
        "                                 valid_area_proc = counts['total'] - counts['errors']\n",
        "                                 print(f\"  - {area}: {acc:.2f}% ({counts['correct']} de {valid_area_proc} válidas / {counts['total']} total / {counts['errors']} erros IA)\")\n",
        "                             else:\n",
        "                                 print(f\"  - {area}: Nenhuma questão processada.\")\n",
        "                    else:\n",
        "                         print(\"  Nenhuma questão encontrada para as áreas especificadas.\")\n",
        "\n",
        "                    print(f\"\\nResultados detalhados salvos em: {OUTPUT_CSV_FILE}\")\n",
        "                else:\n",
        "                    print(\"Nenhuma questão selecionada para processamento.\")\n",
        "        else:\n",
        "            print(\"Não foi possível carregar os dados do JSON.\")\n",
        "\n",
        "    print(\"\\n--- Fim do Script ---\")"
      ]
    }
  ]
}